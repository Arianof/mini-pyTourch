{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "ArHC9dempESZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rimgl54Zf-rR"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Our Mini PyTorch Computation Graph\n",
        "\n",
        "In this mini PyTorch project, I've built a simple tool to visualize the computation graphs that form during tensor operations. This helps illustrate how tensors interact and how gradients flow during backpropagation.\n",
        "\n",
        "### `trace(root)`\n",
        "- **Purpose:**  \n",
        "  Recursively collects all tensors (nodes) and their relationships (edges) starting from a given root tensor.\n",
        "  \n",
        "- **How It Works:**  \n",
        "  It follows the chain of parent tensors (i.e., the tensors used to create a given tensor) and accumulates the connections between them.\n",
        "\n",
        "### `draw_dot(root, format='svg', rankdir='LR')`\n",
        "- **Purpose:**  \n",
        "  Uses Graphviz to draw the computation graph, making it easier to debug and understand how operations build up the final result.\n",
        "  \n",
        "- **Features:**  \n",
        "  - Each tensor is shown as a node with its label, data value, and gradient.\n",
        "  - Operations (e.g., addition, multiplication) are visualized as intermediate nodes.\n",
        "  - The `rankdir` parameter lets you choose between left-to-right (`LR`) or top-to-bottom (`TB`) layouts.\n",
        "  \n",
        "This tool is especially handy for visualizing the flow of data and gradients in our mini PyTorch, which is essential for debugging and learning the inner workings of automatic differentiation.\n"
      ],
      "metadata": {
        "id": "BeCKp_Edn1AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "\n",
        "def trace(root):\n",
        "    nodes, edges = set(), set()\n",
        "\n",
        "    def build(v):\n",
        "        if v not in nodes:\n",
        "            nodes.add(v)\n",
        "            for child in v.parents:\n",
        "                edges.add((child, v))\n",
        "                build(child)\n",
        "\n",
        "    build(root)\n",
        "    return nodes, edges\n",
        "\n",
        "\n",
        "def draw_dot(root, format='svg', rankdir='LR'):\n",
        "    \"\"\"\n",
        "    format: png | svg | ...\n",
        "    rankdir: TB (top to bottom graph) | LR (left to right)\n",
        "    \"\"\"\n",
        "    assert rankdir in ['LR', 'TB']\n",
        "    nodes, edges = trace(root)\n",
        "    dot = Digraph(format=format, graph_attr={'rankdir': rankdir})  # , node_attr={'rankdir': 'TB'})\n",
        "\n",
        "    for n in nodes:\n",
        "        dot.node(name=str(id(n)), label=\"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape='record')\n",
        "        if n.creation_op:\n",
        "            dot.node(name=str(id(n)) + n.creation_op, label=n.creation_op)\n",
        "            dot.edge(str(id(n)) + n.creation_op, str(id(n)))\n",
        "\n",
        "    for n1, n2 in edges:\n",
        "        dot.edge(str(id(n1)), str(id(n2)) + n2.creation_op)\n",
        "\n",
        "    return dot"
      ],
      "metadata": {
        "id": "NtKLaKcmj852"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Core Tensor Class\n",
        "\n",
        "The heart of our mini PyTorch project is the `Tensor` class, which encapsulates both data and gradient information. It not only performs arithmetic operations but also builds the computation graph needed for automatic differentiation.\n",
        "\n",
        "### Key Features of `Tensor`:\n",
        "- **Data & Gradient:**  \n",
        "  Each tensor stores its value (`data`) and the gradient (`grad`), which is initialized to zero.\n",
        "  \n",
        "- **Operation Tracking:**  \n",
        "  - **Parents:** Tensors that were used to create the current tensor.\n",
        "  - **Creation Operation:** A label that records which operation produced this tensor (e.g., \"add\", \"mul\").\n",
        "  \n",
        "- **Arithmetic Operations:**  \n",
        "  The class supports basic operations such as addition, subtraction, multiplication, division, and power.  \n",
        "  - For each operation, a new `Tensor` is created.\n",
        "  - A custom backward function is attached to this new tensor, which defines how gradients should flow back to the input tensors.\n",
        "  \n",
        "- **Backpropagation:**  \n",
        "  The `.backward()` method triggers a backward pass:\n",
        "  - It sets the gradient of the final tensor to 1.\n",
        "  - Using topological sorting, it computes gradients for all preceding tensors in the correct order.\n",
        "  \n",
        "This design mirrors the fundamentals of PyTorch’s autograd engine, allowing us to compute gradients automatically during the training of neural networks.\n"
      ],
      "metadata": {
        "id": "xRkw1pdvkR_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tensor:\n",
        "    def __init__(self, data, parents=[], creation_op=None, label = None):\n",
        "        self.data = data\n",
        "        self.grad = 0.0\n",
        "        self.parents = parents\n",
        "        self.creation_op = creation_op\n",
        "        self.label = label\n",
        "\n",
        "        self._backward = lambda : None\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.grad = 0.0\n",
        "\n",
        "\n",
        "    def __add__(self, other):\n",
        "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
        "\n",
        "\n",
        "        result_data = Tensor(self.data + other.data, parents=[self, other], creation_op=\"add\")\n",
        "\n",
        "\n",
        "        def backward():\n",
        "            self.grad = 1 * result_data.grad\n",
        "            other.grad = 1 * result_data.grad\n",
        "\n",
        "        result_data._backward = backward\n",
        "\n",
        "\n",
        "        return result_data\n",
        "\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
        "\n",
        "        result_data = Tensor(self.data - other.data, parents=[self, other], creation_op=\"sub\")\n",
        "\n",
        "        def backward():\n",
        "            self.grad = 1 * result_data.grad\n",
        "            other.grad = -1 * result_data.grad\n",
        "\n",
        "        result_data._backward = backward\n",
        "\n",
        "        return result_data\n",
        "\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
        "\n",
        "        result_data = Tensor(self.data * other.data, parents=[self, other], creation_op=\"mul\")\n",
        "\n",
        "        def backward():\n",
        "            self.grad = other.data * result_data.grad\n",
        "            other.grad = self.data * result_data.grad\n",
        "\n",
        "        result_data._backward = backward\n",
        "\n",
        "        return result_data\n",
        "\n",
        "    def __truediv__(self, other):\n",
        "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
        "\n",
        "        result_data = Tensor(self.data / other.data, parents=[self, other], creation_op=\"div\")\n",
        "\n",
        "        def backward():\n",
        "            self.grad = 1 / other.data * result_data.grad\n",
        "            other.grad = - (self.data / (other.data ** 2)) * result_data.grad\n",
        "\n",
        "        result_data._backward = backward\n",
        "\n",
        "        return result_data\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(data={self.data}, grad={self.grad})\"\n",
        "\n",
        "\n",
        "    def __pow__(self, other):\n",
        "        result_data = Tensor(self.data ** other, parents=[self], creation_op=\"pow_two\")\n",
        "\n",
        "        def backward():\n",
        "            self.grad = other * (self.data ** (other - 1)) * result_data.grad\n",
        "\n",
        "        result_data._backward = backward\n",
        "\n",
        "        return result_data\n",
        "\n",
        "\n",
        "    def backward(self):\n",
        "        self.grad = 1\n",
        "        topo = self.topological_sort()\n",
        "\n",
        "        for tensor in topo:\n",
        "            tensor._backward()\n",
        "\n",
        "\n",
        "\n",
        "    def topological_sort(self):\n",
        "\n",
        "        topo = []\n",
        "        visited = set()\n",
        "\n",
        "        def dfs(tensor):\n",
        "            if tensor not in visited:\n",
        "                visited.add(tensor)\n",
        "                for parent in tensor.parents:\n",
        "                    dfs(parent)\n",
        "                topo.append(tensor)\n",
        "\n",
        "        dfs(self)\n",
        "        return topo[::-1]"
      ],
      "metadata": {
        "id": "IZPcEsk_kJlr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Tensor Class"
      ],
      "metadata": {
        "id": "4u9c3AmVkVhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = Tensor(2, label='a')\n",
        "b = Tensor(3, label='b')\n",
        "\n",
        "c = a * b; c.label = 'c'\n",
        "draw_dot(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "wC7U4yVkkPKP",
        "outputId": "e1bbd2ee-8f30-4e56-88dd-63dceb737c8d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"504pt\" height=\"100pt\"\n viewBox=\"0.00 0.00 504.00 100.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 96)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-96 500,-96 500,4 -4,4\"/>\n<!-- 136971757267856 -->\n<g id=\"node1\" class=\"node\">\n<title>136971757267856</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"311,-27.5 311,-63.5 496,-63.5 496,-27.5 311,-27.5\"/>\n<text text-anchor=\"middle\" x=\"322.5\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">c</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"334,-27.5 334,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"374\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 6.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"414,-27.5 414,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"455\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.0000</text>\n</g>\n<!-- 136971757267856mul -->\n<g id=\"node2\" class=\"node\">\n<title>136971757267856mul</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"248\" cy=\"-45.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"248\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">mul</text>\n</g>\n<!-- 136971757267856mul&#45;&gt;136971757267856 -->\n<g id=\"edge1\" class=\"edge\">\n<title>136971757267856mul&#45;&gt;136971757267856</title>\n<path fill=\"none\" stroke=\"black\" d=\"M275.04,-45.5C282.58,-45.5 291.3,-45.5 300.57,-45.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"300.81,-49 310.81,-45.5 300.81,-42 300.81,-49\"/>\n</g>\n<!-- 136971757267344 -->\n<g id=\"node3\" class=\"node\">\n<title>136971757267344</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-55.5 0,-91.5 185,-91.5 185,-55.5 0,-55.5\"/>\n<text text-anchor=\"middle\" x=\"11.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"23,-55.5 23,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 3.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"103,-55.5 103,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"144\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.0000</text>\n</g>\n<!-- 136971757267344&#45;&gt;136971757267856mul -->\n<g id=\"edge3\" class=\"edge\">\n<title>136971757267344&#45;&gt;136971757267856mul</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.01,-56.81C194.49,-55.08 203.66,-53.41 211.9,-51.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"212.6,-55.33 221.81,-50.09 211.35,-48.45 212.6,-55.33\"/>\n</g>\n<!-- 136971757262352 -->\n<g id=\"node4\" class=\"node\">\n<title>136971757262352</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-36.5 185,-36.5 185,-0.5 0,-0.5\"/>\n<text text-anchor=\"middle\" x=\"11.5\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"23,-0.5 23,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"103,-0.5 103,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"144\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.0000</text>\n</g>\n<!-- 136971757262352&#45;&gt;136971757267856mul -->\n<g id=\"edge2\" class=\"edge\">\n<title>136971757262352&#45;&gt;136971757267856mul</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.01,-34.6C194.49,-36.26 203.66,-37.88 211.9,-39.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"211.36,-42.78 221.81,-41.07 212.57,-35.89 211.36,-42.78\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7c9338ee5ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.backward()\n",
        "\n",
        "draw_dot(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "7sDStG8nkYno",
        "outputId": "8cb5b2b5-c70a-4838-ad4c-625fb14a363e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"504pt\" height=\"100pt\"\n viewBox=\"0.00 0.00 504.00 100.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 96)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-96 500,-96 500,4 -4,4\"/>\n<!-- 136971757267856 -->\n<g id=\"node1\" class=\"node\">\n<title>136971757267856</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"311,-27.5 311,-63.5 496,-63.5 496,-27.5 311,-27.5\"/>\n<text text-anchor=\"middle\" x=\"322.5\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">c</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"334,-27.5 334,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"374\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 6.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"414,-27.5 414,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"455\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 136971757267856mul -->\n<g id=\"node2\" class=\"node\">\n<title>136971757267856mul</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"248\" cy=\"-45.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"248\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">mul</text>\n</g>\n<!-- 136971757267856mul&#45;&gt;136971757267856 -->\n<g id=\"edge1\" class=\"edge\">\n<title>136971757267856mul&#45;&gt;136971757267856</title>\n<path fill=\"none\" stroke=\"black\" d=\"M275.04,-45.5C282.58,-45.5 291.3,-45.5 300.57,-45.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"300.81,-49 310.81,-45.5 300.81,-42 300.81,-49\"/>\n</g>\n<!-- 136971757267344 -->\n<g id=\"node3\" class=\"node\">\n<title>136971757267344</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-55.5 0,-91.5 185,-91.5 185,-55.5 0,-55.5\"/>\n<text text-anchor=\"middle\" x=\"11.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"23,-55.5 23,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 3.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"103,-55.5 103,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"144\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 2.0000</text>\n</g>\n<!-- 136971757267344&#45;&gt;136971757267856mul -->\n<g id=\"edge3\" class=\"edge\">\n<title>136971757267344&#45;&gt;136971757267856mul</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.01,-56.81C194.49,-55.08 203.66,-53.41 211.9,-51.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"212.6,-55.33 221.81,-50.09 211.35,-48.45 212.6,-55.33\"/>\n</g>\n<!-- 136971757262352 -->\n<g id=\"node4\" class=\"node\">\n<title>136971757262352</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-36.5 185,-36.5 185,-0.5 0,-0.5\"/>\n<text text-anchor=\"middle\" x=\"11.5\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"23,-0.5 23,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"103,-0.5 103,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"144\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 3.0000</text>\n</g>\n<!-- 136971757262352&#45;&gt;136971757267856mul -->\n<g id=\"edge2\" class=\"edge\">\n<title>136971757262352&#45;&gt;136971757267856mul</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.01,-34.6C194.49,-36.26 203.66,-37.88 211.9,-39.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"211.36,-42.78 221.81,-41.07 212.57,-35.89 211.36,-42.78\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7c9338d32610>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Activation Functions with Class F\n",
        "\n",
        "Non-linear activation functions are a core component in neural networks. In our mini PyTorch project, I’ve implemented the hyperbolic tangent (tanh) function inside a helper class `F`.\n",
        "\n",
        "### `F.tanh(x)`:\n",
        "- **Input:**  \n",
        "  The function expects a `Tensor` as input.\n",
        "  \n",
        "- **Forward Pass:**  \n",
        "  It computes the tanh of the tensor’s data using Python’s `math.tanh`, and wraps the result in a new `Tensor`.  \n",
        "  - The new tensor records the original tensor as its parent and labels the operation as `\"tanh\"`.\n",
        "  \n",
        "- **Backward Pass:**  \n",
        "  The derivative of tanh, given by \\(1 - \\tanh(x)^2\\), is used to correctly propagate gradients back to the input tensor.\n",
        "  \n",
        "This activation function enriches our mini PyTorch by enabling non-linear transformations, which are vital for building complex and powerful neural network models.\n"
      ],
      "metadata": {
        "id": "5M_YpDjuo_8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class F:\n",
        "    @staticmethod\n",
        "    def tanh(x):\n",
        "        if isinstance(x, Tensor):\n",
        "            result_data = Tensor(math.tanh(x.data), parents=[x], creation_op=\"tanh\")\n",
        "\n",
        "            def backward():\n",
        "                x.grad = (1 - math.tanh(x.data) ** 2) * result_data.grad\n",
        "\n",
        "            result_data._backward = backward\n",
        "\n",
        "            return result_data"
      ],
      "metadata": {
        "id": "0Yw2DGzzoTl0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a Simple Neuron in Our Mini PyTorch\n",
        "\n",
        "Now that we have our `Tensor` class and activation functions, let’s build a fundamental component of neural networks: a **Neuron**. In this mini PyTorch project, a neuron is a simple unit that takes multiple inputs, applies weights and a bias, and passes the result through an activation function.\n",
        "\n",
        "### `Neuron(input_size)`\n",
        "- **Weights & Bias:**  \n",
        "  - Each neuron has a list of weights (`self.weights`), initialized randomly between -1 and 1.\n",
        "  - A bias term (`self.bias`) is also initialized randomly.\n",
        "  - Both weights and bias are `Tensor` objects, meaning they support automatic differentiation.\n",
        "\n",
        "### `forward(x)`\n",
        "- **Computes the Neuron’s Output:**  \n",
        "  - The neuron first starts with the bias term.\n",
        "  - Each input (`x_i`) is multiplied by its corresponding weight (`w_i`), and the results are summed.\n",
        "  - The sum is then passed through the **tanh activation function** for non-linearity.\n",
        "\n",
        "### `__call__(x)`\n",
        "- **Shortcut for Forward Pass:**  \n",
        "  - This makes the neuron callable like a function: `neuron(x)` instead of `neuron.forward(x)`, improving code readability.\n",
        "\n",
        "### `parameters()`\n",
        "- **Returns Learnable Parameters:**  \n",
        "  - This method gathers all tunable parameters (weights and bias), making it easy to update them during training.\n",
        "\n",
        "This `Neuron` class is a foundational building block for constructing larger models like fully connected layers and neural networks. Next, we can stack multiple neurons together to form more complex architectures!\n"
      ],
      "metadata": {
        "id": "e-MxSy-FpY65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "    def __init__(self, input_size):\n",
        "        self.weights = [Tensor(random.uniform(-1, 1)) for _ in range(input_size)]\n",
        "        self.bias = Tensor(random.uniform(-1, 1))\n",
        "    def forward(self, x):\n",
        "        res = self.bias\n",
        "        for w_i, x_i in zip(self.weights, x):\n",
        "            res += w_i * x_i\n",
        "        return F.tanh(res)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "    def parameters(self):\n",
        "        return self.weights + [self.bias]"
      ],
      "metadata": {
        "id": "5_35SUHLogbu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a Neural Network Layer in Our Mini PyTorch\n",
        "\n",
        "Now that we have a single `Neuron` class, the next step is to group multiple neurons together into a **Layer**. This class represents a fully connected (dense) layer, where each neuron receives the same set of inputs but has its own unique weights and bias.\n",
        "\n",
        "### `Layer(input_size, output_size)`\n",
        "- **Creates `output_size` neurons:**  \n",
        "  - Each neuron in the layer takes `input_size` inputs.\n",
        "  - The layer is simply a list of `Neuron` objects.\n",
        "\n",
        "### `forward(x)`\n",
        "- **Computes the Layer’s Output:**  \n",
        "  - It calls each neuron with the same input `x` and collects their outputs into a list.\n",
        "  - If the layer has only one neuron, it returns a single value instead of a list.\n",
        "\n",
        "### `__call__(x)`\n",
        "- **Shortcut for Forward Pass:**  \n",
        "  - Enables calling the layer like a function: `layer(x)` instead of `layer.forward(x)`, improving readability.\n",
        "\n",
        "### `parameters()`\n",
        "- **Gathers All Learnable Parameters:**  \n",
        "  - Loops through all neurons and collects their weights and biases.\n",
        "  - This makes it easy to access all the parameters for optimization during training.\n",
        "\n",
        "This `Layer` class allows us to build deep networks by stacking multiple layers on top of each other. The next step is to combine layers into a full **Neural Network model**!\n"
      ],
      "metadata": {
        "id": "JkF4yiTBpkN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.neurons = [Neuron(input_size) for _ in range(output_size)]\n",
        "    def forward(self, x):\n",
        "        res = [neuron(x) for neuron in self.neurons]\n",
        "        return res[0] if len(res) == 1 else res\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "    def parameters(self):\n",
        "        params = []\n",
        "        for neuron in self.neurons:\n",
        "            params += neuron.parameters()\n",
        "        return params"
      ],
      "metadata": {
        "id": "pEQ2rztSpKT6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Multi-Layer Perceptron (MLP)\n",
        "\n",
        "Taking our project a step further, I've put together a simple Multi-Layer Perceptron (MLP) class that builds on our `Layer` class. An MLP is essentially a stack of layers that processes inputs through a series of transformations to produce outputs.\n",
        "\n",
        "### `MLP(input_size, layer_sizes)`\n",
        "- **Initialization:**  \n",
        "  - The constructor takes the input size and a list of layer sizes.  \n",
        "  - It automatically creates the architecture by constructing layers where the number of neurons in each layer is specified by `layer_sizes`.\n",
        "  - The total configuration starts with the input size, followed by each layer's size, defining how data flows from one layer to the next.\n",
        "\n",
        "### `forward(x)`\n",
        "- **Forward Pass:**  \n",
        "  - The input `x` is sequentially passed through each layer in the network.\n",
        "  - Each layer transforms the data, and the output of one layer becomes the input to the next.\n",
        "  - The final output is returned, representing the network's prediction or transformation.\n",
        "\n",
        "### `__call__(x)`\n",
        "- **Convenience:**  \n",
        "  - This makes the MLP callable like a function, so you can simply write `mlp(x)` to perform a forward pass.\n",
        "\n",
        "### `parameters()`\n",
        "- **Collecting Parameters:**  \n",
        "  - This method aggregates all learnable parameters (weights and biases) from every layer in the network.\n",
        "  - It's useful for tasks like updating weights during training using optimization algorithms.\n",
        "\n",
        "This `MLP` class encapsulates the essence of a neural network, allowing us to build and experiment with different architectures in our mini PyTorch project. It demonstrates how simple components can be combined to create complex models, much like in full-fledged deep learning frameworks.\n"
      ],
      "metadata": {
        "id": "l2XIfxDbpvge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self, input_size, layer_sizes):\n",
        "        layer_total = [input_size] + layer_sizes\n",
        "        self.layers = [Layer(layer_total[i], layer_total[i + 1]) for i in range(len(layer_sizes))]\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "    def parameters(self):\n",
        "        params = []\n",
        "        for layer in self.layers:\n",
        "            params += layer.parameters()\n",
        "        return params"
      ],
      "metadata": {
        "id": "x8QzEs-0pe68"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a Basic Optimizer\n",
        "\n",
        "In our mini PyTorch project, we've built a simple optimizer class that mimics the behavior of standard gradient descent. This class is responsible for updating the parameters of our neural network based on their gradients.\n",
        "\n",
        "### `Optimizer(parameters, lr)`\n",
        "- **Parameters:**  \n",
        "  - The optimizer takes a list of parameters (learnable weights and biases) from our model.\n",
        "  - It also takes a learning rate (`lr`) which controls the size of the updates during training.\n",
        "\n",
        "### Methods:\n",
        "- **`zero_grad()`**  \n",
        "  - Resets the gradients of all parameters to zero.  \n",
        "  - This is crucial before each new iteration of training to ensure that gradients are not accumulated from previous iterations.\n",
        "\n",
        "- **`step()`**  \n",
        "  - Updates each parameter by subtracting the product of its gradient and the learning rate.  \n",
        "  - This is the essence of the gradient descent update rule.\n",
        "\n",
        "This basic optimizer is a foundational tool for training our model. By repeatedly applying `zero_grad()` and `step()` during training, we can iteratively minimize the loss function and improve the model's performance.\n"
      ],
      "metadata": {
        "id": "gCHBIdQFqDPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer:\n",
        "\n",
        "    def __init__(self, parameters, lr):\n",
        "        self.parameters = parameters\n",
        "        self.lr = lr\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for param in self.parameters:\n",
        "            param.zero_grad()\n",
        "\n",
        "    def step(self):\n",
        "        for param in self.parameters:\n",
        "            param.data -= param.grad * self.lr"
      ],
      "metadata": {
        "id": "fIX_A90Pp2ug"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions\n",
        "\n"
      ],
      "metadata": {
        "id": "2b4KBNWSqPb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Predictions with Our Model\n",
        "\n",
        "The `make_predictions` function serves as a simple interface to obtain predictions from our mini PyTorch model on a dataset.\n",
        "\n",
        "### `make_predictions(model, X)`\n",
        "- **Purpose:**  \n",
        "  - Iterates through each example in the input dataset `X` and generates predictions using the provided `model`.\n",
        "\n",
        "- **How It Works:**  \n",
        "  - For each input `x` in `X`, the function calls the model (using its `__call__` method) to compute the prediction.\n",
        "  - It collects all the predictions in a list and returns this list.\n",
        "\n",
        "This function streamlines the process of generating outputs from the model, making it easy to evaluate and work with predictions on a batch of data.\n"
      ],
      "metadata": {
        "id": "_G458DkZtjTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, X):\n",
        "    preds = []\n",
        "    for x in X:\n",
        "        pred = model(x)\n",
        "        preds.append(pred)\n",
        "    return preds"
      ],
      "metadata": {
        "id": "Xoq8UmyGqFbS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Loss Function\n",
        "\n",
        "To train our mini PyTorch model, we need a way to quantify how far our predictions are from the true values. Here, I’ve implemented a simple mean squared error (MSE) loss function.\n",
        "\n",
        "### `calculate_loss(y_true, y_pred)`\n",
        "- **Purpose:**  \n",
        "  - Computes the mean squared error between the predicted outputs (`y_pred`) and the actual targets (`y_true`).\n",
        "\n",
        "- **How It Works:**  \n",
        "  - Initializes the loss as a `Tensor` with value 0.\n",
        "  - Iterates over pairs of true and predicted values, computing the squared difference for each pair.\n",
        "  - Accumulates these squared differences into the loss.\n",
        "  - Finally, divides the total loss by the number of examples to compute the average loss.\n",
        "\n",
        "This function is essential for measuring the performance of our model and guiding the optimization process during training.\n"
      ],
      "metadata": {
        "id": "VKosPx-ete73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(y_true, y_pred):\n",
        "\n",
        "    loss = Tensor(0)\n",
        "\n",
        "    for y_t, y_p in zip(y_true, y_pred):\n",
        "        loss += (y_p - y_t) ** 2\n",
        "\n",
        "    return loss / len(y_true)"
      ],
      "metadata": {
        "id": "Fu5WJIb2qJ9S"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test and Results"
      ],
      "metadata": {
        "id": "jFfQhiQMqeIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "OXwFSF1owe_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we test our simple mini pyTourch by making a MLP and run a classification task on Iris dataset"
      ],
      "metadata": {
        "id": "vhdceOqkqkIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./iris.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DkLDZ4jWqMoA",
        "outputId": "78de85a1-f834-41b8-fcc6-bd1348b8bfeb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
              "0             5.1          3.5           1.4          0.2     Setosa\n",
              "1             4.9          3.0           1.4          0.2     Setosa\n",
              "2             4.7          3.2           1.3          0.2     Setosa\n",
              "3             4.6          3.1           1.5          0.2     Setosa\n",
              "4             5.0          3.6           1.4          0.2     Setosa\n",
              "..            ...          ...           ...          ...        ...\n",
              "145           6.7          3.0           5.2          2.3  Virginica\n",
              "146           6.3          2.5           5.0          1.9  Virginica\n",
              "147           6.5          3.0           5.2          2.0  Virginica\n",
              "148           6.2          3.4           5.4          2.3  Virginica\n",
              "149           5.9          3.0           5.1          1.8  Virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-100503a7-e259-4da7-99bf-cd9df32a0178\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-100503a7-e259-4da7-99bf-cd9df32a0178')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-100503a7-e259-4da7-99bf-cd9df32a0178 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-100503a7-e259-4da7-99bf-cd9df32a0178');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6eb6b32e-79da-49c4-84e9-75f83e8a3ecd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6eb6b32e-79da-49c4-84e9-75f83e8a3ecd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6eb6b32e-79da-49c4-84e9-75f83e8a3ecd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e52dcfcc-89ce-43a9-adff-a24a68fd51b3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e52dcfcc-89ce-43a9-adff-a24a68fd51b3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.435866284936698,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7652982332594667,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7622376689603465,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variety\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Setosa\",\n          \"Versicolor\",\n          \"Virginica\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step we run a label encoding to make our dataset feedable to our neural network"
      ],
      "metadata": {
        "id": "UwB55ntnqx6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variety_encoding = {\"Setosa\":1,\"Versicolor\":2,\"Virginica\":3}\n",
        "df[\"variety\"] = df[\"variety\"].apply(variety_encoding.get)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KyFtp8j7qtWK",
        "outputId": "46812ec3-765b-4c07-a64a-b519c64bdbab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal.length  sepal.width  petal.length  petal.width  variety\n",
              "0             5.1          3.5           1.4          0.2        1\n",
              "1             4.9          3.0           1.4          0.2        1\n",
              "2             4.7          3.2           1.3          0.2        1\n",
              "3             4.6          3.1           1.5          0.2        1\n",
              "4             5.0          3.6           1.4          0.2        1\n",
              "..            ...          ...           ...          ...      ...\n",
              "145           6.7          3.0           5.2          2.3        3\n",
              "146           6.3          2.5           5.0          1.9        3\n",
              "147           6.5          3.0           5.2          2.0        3\n",
              "148           6.2          3.4           5.4          2.3        3\n",
              "149           5.9          3.0           5.1          1.8        3\n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46b2af2e-b5f9-4db3-a023-8b6626450361\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46b2af2e-b5f9-4db3-a023-8b6626450361')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46b2af2e-b5f9-4db3-a023-8b6626450361 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46b2af2e-b5f9-4db3-a023-8b6626450361');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2546776-589f-4a70-83b9-211437f5063f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2546776-589f-4a70-83b9-211437f5063f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2546776-589f-4a70-83b9-211437f5063f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b99df900-cc8b-4a05-9ec0-449d1e307f22\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b99df900-cc8b-4a05-9ec0-449d1e307f22 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.435866284936698,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7652982332594667,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7622376689603465,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variety\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we run a minmax scaler to make our data range more standard to get better results"
      ],
      "metadata": {
        "id": "O41vzql5rAsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "min_max_df = min_max_scaler.fit_transform(df)\n",
        "new_df = pd.DataFrame(min_max_df)\n",
        "new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mvv4Tw7EqvSm",
        "outputId": "c8540c66-3cb1-44af-8a65-03d08ab8882e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3    4\n",
              "0    0.222222  0.625000  0.067797  0.041667  0.0\n",
              "1    0.166667  0.416667  0.067797  0.041667  0.0\n",
              "2    0.111111  0.500000  0.050847  0.041667  0.0\n",
              "3    0.083333  0.458333  0.084746  0.041667  0.0\n",
              "4    0.194444  0.666667  0.067797  0.041667  0.0\n",
              "..        ...       ...       ...       ...  ...\n",
              "145  0.666667  0.416667  0.711864  0.916667  1.0\n",
              "146  0.555556  0.208333  0.677966  0.750000  1.0\n",
              "147  0.611111  0.416667  0.711864  0.791667  1.0\n",
              "148  0.527778  0.583333  0.745763  0.916667  1.0\n",
              "149  0.444444  0.416667  0.694915  0.708333  1.0\n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-495b4fa0-f1f6-490d-b1c9-d3f21a19ecd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.067797</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.067797</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.050847</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.084746</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.194444</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.067797</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.711864</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.677966</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.711864</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.745763</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.694915</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-495b4fa0-f1f6-490d-b1c9-d3f21a19ecd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-495b4fa0-f1f6-490d-b1c9-d3f21a19ecd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-495b4fa0-f1f6-490d-b1c9-d3f21a19ecd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f436c364-8a43-4a97-a046-76b33cd3838b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f436c364-8a43-4a97-a046-76b33cd3838b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f436c364-8a43-4a97-a046-76b33cd3838b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ad839cc2-6458-4139-a869-a2cc2b4e9b58\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('new_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ad839cc2-6458-4139-a869-a2cc2b4e9b58 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('new_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_df",
              "summary": "{\n  \"name\": \"new_df\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23001836888273966,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          0.5277777777777779,\n          0.05555555555555558,\n          0.36111111111111094\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1816109520569575,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0.12499999999999989,\n          0.8333333333333333,\n          0.625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2992030903829601,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          0.9661016949152543,\n          0.47457627118644063,\n          0.4576271186440678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31759902873347784,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.04166666666666667,\n          0.4583333333333333,\n          0.5000000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40961596025952024,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.5,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spliting Test and Train"
      ],
      "metadata": {
        "id": "IZdEuQxDrnno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = new_df[4]\n",
        "X = new_df.drop(4, axis=1)\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ez30tFtOq_ke"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declaring our desired MLP"
      ],
      "metadata": {
        "id": "uO5RVWxLrjC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 4 # Number of features in the input layer\n",
        "layer_sizes = [3, 4, 4 ,1] # Number of neurons in each hidden and output layer\n",
        "\n",
        "model = MLP(input_size, layer_sizes)\n",
        "\n",
        "params = model.parameters()\n",
        "\n",
        "optim = Optimizer(params, 0.15)"
      ],
      "metadata": {
        "id": "r7ji-uMZrgaV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing Training"
      ],
      "metadata": {
        "id": "h8aZSxQ5rq0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 1000\n",
        "\n",
        "\n",
        "for i in range(n_epochs):\n",
        "\n",
        "    y_hats = make_predictions(model, X_train)\n",
        "\n",
        "    loss = calculate_loss(y_train, y_hats)\n",
        "\n",
        "    print(f\"loss in iteration{i}: {loss}\")\n",
        "\n",
        "    optim.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optim.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpfXPFEOrSDl",
        "outputId": "8797d4dd-c788-45bd-de09-ca199123a1b0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in iteration0: Tensor(data=1.42938659449927, grad=0.0)\n",
            "loss in iteration1: Tensor(data=1.427120345375033, grad=0.0)\n",
            "loss in iteration2: Tensor(data=1.4248446237129384, grad=0.0)\n",
            "loss in iteration3: Tensor(data=1.4225593828600254, grad=0.0)\n",
            "loss in iteration4: Tensor(data=1.4202645760270947, grad=0.0)\n",
            "loss in iteration5: Tensor(data=1.417960156291646, grad=0.0)\n",
            "loss in iteration6: Tensor(data=1.4156460766009087, grad=0.0)\n",
            "loss in iteration7: Tensor(data=1.4133222897749853, grad=0.0)\n",
            "loss in iteration8: Tensor(data=1.4109887485101151, grad=0.0)\n",
            "loss in iteration9: Tensor(data=1.408645405382044, grad=0.0)\n",
            "loss in iteration10: Tensor(data=1.4062922128495134, grad=0.0)\n",
            "loss in iteration11: Tensor(data=1.4039291232578728, grad=0.0)\n",
            "loss in iteration12: Tensor(data=1.4015560888428196, grad=0.0)\n",
            "loss in iteration13: Tensor(data=1.3991730617342533, grad=0.0)\n",
            "loss in iteration14: Tensor(data=1.3967799939602688, grad=0.0)\n",
            "loss in iteration15: Tensor(data=1.394376837451282, grad=0.0)\n",
            "loss in iteration16: Tensor(data=1.3919635440442826, grad=0.0)\n",
            "loss in iteration17: Tensor(data=1.3895400654872345, grad=0.0)\n",
            "loss in iteration18: Tensor(data=1.3871063534436159, grad=0.0)\n",
            "loss in iteration19: Tensor(data=1.3846623594970986, grad=0.0)\n",
            "loss in iteration20: Tensor(data=1.382208035156381, grad=0.0)\n",
            "loss in iteration21: Tensor(data=1.379743331860172, grad=0.0)\n",
            "loss in iteration22: Tensor(data=1.37726820098233, grad=0.0)\n",
            "loss in iteration23: Tensor(data=1.3747825938371592, grad=0.0)\n",
            "loss in iteration24: Tensor(data=1.372286461684866, grad=0.0)\n",
            "loss in iteration25: Tensor(data=1.3697797557371871, grad=0.0)\n",
            "loss in iteration26: Tensor(data=1.3672624271631826, grad=0.0)\n",
            "loss in iteration27: Tensor(data=1.3647344270952002, grad=0.0)\n",
            "loss in iteration28: Tensor(data=1.3621957066350185, grad=0.0)\n",
            "loss in iteration29: Tensor(data=1.3596462168601826, grad=0.0)\n",
            "loss in iteration30: Tensor(data=1.357085908830496, grad=0.0)\n",
            "loss in iteration31: Tensor(data=1.3545147335947327, grad=0.0)\n",
            "loss in iteration32: Tensor(data=1.3519326421975226, grad=0.0)\n",
            "loss in iteration33: Tensor(data=1.3493395856864383, grad=0.0)\n",
            "loss in iteration34: Tensor(data=1.3467355151192844, grad=0.0)\n",
            "loss in iteration35: Tensor(data=1.344120381571595, grad=0.0)\n",
            "loss in iteration36: Tensor(data=1.3414941361443338, grad=0.0)\n",
            "loss in iteration37: Tensor(data=1.3388567299718155, grad=0.0)\n",
            "loss in iteration38: Tensor(data=1.3362081142298383, grad=0.0)\n",
            "loss in iteration39: Tensor(data=1.3335482401440497, grad=0.0)\n",
            "loss in iteration40: Tensor(data=1.330877058998527, grad=0.0)\n",
            "loss in iteration41: Tensor(data=1.3281945221446056, grad=0.0)\n",
            "loss in iteration42: Tensor(data=1.325500581009929, grad=0.0)\n",
            "loss in iteration43: Tensor(data=1.3227951871077548, grad=0.0)\n",
            "loss in iteration44: Tensor(data=1.3200782920464929, grad=0.0)\n",
            "loss in iteration45: Tensor(data=1.3173498475395156, grad=0.0)\n",
            "loss in iteration46: Tensor(data=1.3146098054151991, grad=0.0)\n",
            "loss in iteration47: Tensor(data=1.3118581176272528, grad=0.0)\n",
            "loss in iteration48: Tensor(data=1.3090947362652938, grad=0.0)\n",
            "loss in iteration49: Tensor(data=1.3063196135657111, grad=0.0)\n",
            "loss in iteration50: Tensor(data=1.3035327019227954, grad=0.0)\n",
            "loss in iteration51: Tensor(data=1.3007339539001601, grad=0.0)\n",
            "loss in iteration52: Tensor(data=1.2979233222424418, grad=0.0)\n",
            "loss in iteration53: Tensor(data=1.295100759887304, grad=0.0)\n",
            "loss in iteration54: Tensor(data=1.2922662199777362, grad=0.0)\n",
            "loss in iteration55: Tensor(data=1.2894196558746573, grad=0.0)\n",
            "loss in iteration56: Tensor(data=1.286561021169829, grad=0.0)\n",
            "loss in iteration57: Tensor(data=1.28369026969909, grad=0.0)\n",
            "loss in iteration58: Tensor(data=1.2808073555559063, grad=0.0)\n",
            "loss in iteration59: Tensor(data=1.2779122331052533, grad=0.0)\n",
            "loss in iteration60: Tensor(data=1.275004856997834, grad=0.0)\n",
            "loss in iteration61: Tensor(data=1.2720851821846317, grad=0.0)\n",
            "loss in iteration62: Tensor(data=1.269153163931808, grad=0.0)\n",
            "loss in iteration63: Tensor(data=1.2662087578359622, grad=0.0)\n",
            "loss in iteration64: Tensor(data=1.263251919839737, grad=0.0)\n",
            "loss in iteration65: Tensor(data=1.2602826062477925, grad=0.0)\n",
            "loss in iteration66: Tensor(data=1.2573007737431523, grad=0.0)\n",
            "loss in iteration67: Tensor(data=1.2543063794039249, grad=0.0)\n",
            "loss in iteration68: Tensor(data=1.2512993807204054, grad=0.0)\n",
            "loss in iteration69: Tensor(data=1.2482797356125666, grad=0.0)\n",
            "loss in iteration70: Tensor(data=1.2452474024479456, grad=0.0)\n",
            "loss in iteration71: Tensor(data=1.2422023400599354, grad=0.0)\n",
            "loss in iteration72: Tensor(data=1.239144507766473, grad=0.0)\n",
            "loss in iteration73: Tensor(data=1.2360738653891545, grad=0.0)\n",
            "loss in iteration74: Tensor(data=1.2329903732727592, grad=0.0)\n",
            "loss in iteration75: Tensor(data=1.2298939923052084, grad=0.0)\n",
            "loss in iteration76: Tensor(data=1.226784683937949, grad=0.0)\n",
            "loss in iteration77: Tensor(data=1.223662410206784, grad=0.0)\n",
            "loss in iteration78: Tensor(data=1.2205271337531363, grad=0.0)\n",
            "loss in iteration79: Tensor(data=1.2173788178457827, grad=0.0)\n",
            "loss in iteration80: Tensor(data=1.2142174264030217, grad=0.0)\n",
            "loss in iteration81: Tensor(data=1.2110429240153235, grad=0.0)\n",
            "loss in iteration82: Tensor(data=1.207855275968444, grad=0.0)\n",
            "loss in iteration83: Tensor(data=1.204654448267007, grad=0.0)\n",
            "loss in iteration84: Tensor(data=1.2014404076585803, grad=0.0)\n",
            "loss in iteration85: Tensor(data=1.1982131216582335, grad=0.0)\n",
            "loss in iteration86: Tensor(data=1.1949725585735846, grad=0.0)\n",
            "loss in iteration87: Tensor(data=1.1917186875303534, grad=0.0)\n",
            "loss in iteration88: Tensor(data=1.188451478498418, grad=0.0)\n",
            "loss in iteration89: Tensor(data=1.1851709023183767, grad=0.0)\n",
            "loss in iteration90: Tensor(data=1.1818769307286325, grad=0.0)\n",
            "loss in iteration91: Tensor(data=1.1785695363929896, grad=0.0)\n",
            "loss in iteration92: Tensor(data=1.1752486929287889, grad=0.0)\n",
            "loss in iteration93: Tensor(data=1.1719143749355594, grad=0.0)\n",
            "loss in iteration94: Tensor(data=1.1685665580242188, grad=0.0)\n",
            "loss in iteration95: Tensor(data=1.1652052188468067, grad=0.0)\n",
            "loss in iteration96: Tensor(data=1.1618303351267625, grad=0.0)\n",
            "loss in iteration97: Tensor(data=1.1584418856897567, grad=0.0)\n",
            "loss in iteration98: Tensor(data=1.1550398504950752, grad=0.0)\n",
            "loss in iteration99: Tensor(data=1.1516242106675534, grad=0.0)\n",
            "loss in iteration100: Tensor(data=1.1481949485300795, grad=0.0)\n",
            "loss in iteration101: Tensor(data=1.1447520476366548, grad=0.0)\n",
            "loss in iteration102: Tensor(data=1.1412954928060237, grad=0.0)\n",
            "loss in iteration103: Tensor(data=1.137825270155875, grad=0.0)\n",
            "loss in iteration104: Tensor(data=1.1343413671376044, grad=0.0)\n",
            "loss in iteration105: Tensor(data=1.130843772571665, grad=0.0)\n",
            "loss in iteration106: Tensor(data=1.1273324766834765, grad=0.0)\n",
            "loss in iteration107: Tensor(data=1.1238074711399306, grad=0.0)\n",
            "loss in iteration108: Tensor(data=1.1202687490864511, grad=0.0)\n",
            "loss in iteration109: Tensor(data=1.1167163051846454, grad=0.0)\n",
            "loss in iteration110: Tensor(data=1.1131501356505284, grad=0.0)\n",
            "loss in iteration111: Tensor(data=1.1095702382933297, grad=0.0)\n",
            "loss in iteration112: Tensor(data=1.1059766125548594, grad=0.0)\n",
            "loss in iteration113: Tensor(data=1.1023692595494698, grad=0.0)\n",
            "loss in iteration114: Tensor(data=1.0987481821045735, grad=0.0)\n",
            "loss in iteration115: Tensor(data=1.0951133848017318, grad=0.0)\n",
            "loss in iteration116: Tensor(data=1.0914648740183168, grad=0.0)\n",
            "loss in iteration117: Tensor(data=1.0878026579697324, grad=0.0)\n",
            "loss in iteration118: Tensor(data=1.0841267467521862, grad=0.0)\n",
            "loss in iteration119: Tensor(data=1.0804371523860208, grad=0.0)\n",
            "loss in iteration120: Tensor(data=1.0767338888595863, grad=0.0)\n",
            "loss in iteration121: Tensor(data=1.0730169721736618, grad=0.0)\n",
            "loss in iteration122: Tensor(data=1.0692864203863928, grad=0.0)\n",
            "loss in iteration123: Tensor(data=1.0655422536587653, grad=0.0)\n",
            "loss in iteration124: Tensor(data=1.061784494300594, grad=0.0)\n",
            "loss in iteration125: Tensor(data=1.0580131668170059, grad=0.0)\n",
            "loss in iteration126: Tensor(data=1.0542282979554256, grad=0.0)\n",
            "loss in iteration127: Tensor(data=1.0504299167530429, grad=0.0)\n",
            "loss in iteration128: Tensor(data=1.0466180545847443, grad=0.0)\n",
            "loss in iteration129: Tensor(data=1.0427927452115044, grad=0.0)\n",
            "loss in iteration130: Tensor(data=1.0389540248292193, grad=0.0)\n",
            "loss in iteration131: Tensor(data=1.0351019321179573, grad=0.0)\n",
            "loss in iteration132: Tensor(data=1.0312365082916275, grad=0.0)\n",
            "loss in iteration133: Tensor(data=1.0273577971480345, grad=0.0)\n",
            "loss in iteration134: Tensor(data=1.0234658451192982, grad=0.0)\n",
            "loss in iteration135: Tensor(data=1.0195607013226369, grad=0.0)\n",
            "loss in iteration136: Tensor(data=1.015642417611464, grad=0.0)\n",
            "loss in iteration137: Tensor(data=1.011711048626802, grad=0.0)\n",
            "loss in iteration138: Tensor(data=1.0077666518489738, grad=0.0)\n",
            "loss in iteration139: Tensor(data=1.0038092876495504, grad=0.0)\n",
            "loss in iteration140: Tensor(data=0.9998390193435243, grad=0.0)\n",
            "loss in iteration141: Tensor(data=0.9958559132416889, grad=0.0)\n",
            "loss in iteration142: Tensor(data=0.9918600387031834, grad=0.0)\n",
            "loss in iteration143: Tensor(data=0.9878514681881853, grad=0.0)\n",
            "loss in iteration144: Tensor(data=0.983830277310695, grad=0.0)\n",
            "loss in iteration145: Tensor(data=0.9797965448914089, grad=0.0)\n",
            "loss in iteration146: Tensor(data=0.9757503530106144, grad=0.0)\n",
            "loss in iteration147: Tensor(data=0.9716917870610932, grad=0.0)\n",
            "loss in iteration148: Tensor(data=0.9676209358009763, grad=0.0)\n",
            "loss in iteration149: Tensor(data=0.9635378914065245, grad=0.0)\n",
            "loss in iteration150: Tensor(data=0.9594427495247773, grad=0.0)\n",
            "loss in iteration151: Tensor(data=0.9553356093260338, grad=0.0)\n",
            "loss in iteration152: Tensor(data=0.9512165735561261, grad=0.0)\n",
            "loss in iteration153: Tensor(data=0.9470857485884177, grad=0.0)\n",
            "loss in iteration154: Tensor(data=0.942943244475496, grad=0.0)\n",
            "loss in iteration155: Tensor(data=0.9387891750005019, grad=0.0)\n",
            "loss in iteration156: Tensor(data=0.9346236577280347, grad=0.0)\n",
            "loss in iteration157: Tensor(data=0.9304468140545878, grad=0.0)\n",
            "loss in iteration158: Tensor(data=0.9262587692584562, grad=0.0)\n",
            "loss in iteration159: Tensor(data=0.922059652549048, grad=0.0)\n",
            "loss in iteration160: Tensor(data=0.9178495971155488, grad=0.0)\n",
            "loss in iteration161: Tensor(data=0.9136287401748777, grad=0.0)\n",
            "loss in iteration162: Tensor(data=0.9093972230188532, grad=0.0)\n",
            "loss in iteration163: Tensor(data=0.9051551910605258, grad=0.0)\n",
            "loss in iteration164: Tensor(data=0.9009027938795933, grad=0.0)\n",
            "loss in iteration165: Tensor(data=0.8966401852668268, grad=0.0)\n",
            "loss in iteration166: Tensor(data=0.8923675232674556, grad=0.0)\n",
            "loss in iteration167: Tensor(data=0.8880849702234009, grad=0.0)\n",
            "loss in iteration168: Tensor(data=0.8837926928143268, grad=0.0)\n",
            "loss in iteration169: Tensor(data=0.8794908620973867, grad=0.0)\n",
            "loss in iteration170: Tensor(data=0.875179653545627, grad=0.0)\n",
            "loss in iteration171: Tensor(data=0.8708592470849266, grad=0.0)\n",
            "loss in iteration172: Tensor(data=0.8665298271294269, grad=0.0)\n",
            "loss in iteration173: Tensor(data=0.8621915826153427, grad=0.0)\n",
            "loss in iteration174: Tensor(data=0.8578447070330756, grad=0.0)\n",
            "loss in iteration175: Tensor(data=0.8534893984575455, grad=0.0)\n",
            "loss in iteration176: Tensor(data=0.8491258595766502, grad=0.0)\n",
            "loss in iteration177: Tensor(data=0.8447542977177597, grad=0.0)\n",
            "loss in iteration178: Tensor(data=0.8403749248721545, grad=0.0)\n",
            "loss in iteration179: Tensor(data=0.8359879577173234, grad=0.0)\n",
            "loss in iteration180: Tensor(data=0.8315936176370138, grad=0.0)\n",
            "loss in iteration181: Tensor(data=0.8271921307389489, grad=0.0)\n",
            "loss in iteration182: Tensor(data=0.8227837278701191, grad=0.0)\n",
            "loss in iteration183: Tensor(data=0.8183686446295392, grad=0.0)\n",
            "loss in iteration184: Tensor(data=0.813947121378391, grad=0.0)\n",
            "loss in iteration185: Tensor(data=0.8095194032474385, grad=0.0)\n",
            "loss in iteration186: Tensor(data=0.8050857401416295, grad=0.0)\n",
            "loss in iteration187: Tensor(data=0.8006463867417841, grad=0.0)\n",
            "loss in iteration188: Tensor(data=0.7962016025032665, grad=0.0)\n",
            "loss in iteration189: Tensor(data=0.7917516516515497, grad=0.0)\n",
            "loss in iteration190: Tensor(data=0.7872968031745743, grad=0.0)\n",
            "loss in iteration191: Tensor(data=0.7828373308118042, grad=0.0)\n",
            "loss in iteration192: Tensor(data=0.7783735130398827, grad=0.0)\n",
            "loss in iteration193: Tensor(data=0.7739056330547989, grad=0.0)\n",
            "loss in iteration194: Tensor(data=0.7694339787504637, grad=0.0)\n",
            "loss in iteration195: Tensor(data=0.764958842693612, grad=0.0)\n",
            "loss in iteration196: Tensor(data=0.7604805220949363, grad=0.0)\n",
            "loss in iteration197: Tensor(data=0.75599931877636, grad=0.0)\n",
            "loss in iteration198: Tensor(data=0.7515155391343676, grad=0.0)\n",
            "loss in iteration199: Tensor(data=0.7470294940993171, grad=0.0)\n",
            "loss in iteration200: Tensor(data=0.7425414990906295, grad=0.0)\n",
            "loss in iteration201: Tensor(data=0.738051873967804, grad=0.0)\n",
            "loss in iteration202: Tensor(data=0.7335609429771632, grad=0.0)\n",
            "loss in iteration203: Tensor(data=0.7290690346942689, grad=0.0)\n",
            "loss in iteration204: Tensor(data=0.724576481961934, grad=0.0)\n",
            "loss in iteration205: Tensor(data=0.7200836218237682, grad=0.0)\n",
            "loss in iteration206: Tensor(data=0.7155907954531955, grad=0.0)\n",
            "loss in iteration207: Tensor(data=0.711098348077898, grad=0.0)\n",
            "loss in iteration208: Tensor(data=0.7066066288996146, grad=0.0)\n",
            "loss in iteration209: Tensor(data=0.7021159910092766, grad=0.0)\n",
            "loss in iteration210: Tensor(data=0.6976267912974133, grad=0.0)\n",
            "loss in iteration211: Tensor(data=0.6931393903598183, grad=0.0)\n",
            "loss in iteration212: Tensor(data=0.6886541523984228, grad=0.0)\n",
            "loss in iteration213: Tensor(data=0.6841714451173798, grad=0.0)\n",
            "loss in iteration214: Tensor(data=0.6796916396143214, grad=0.0)\n",
            "loss in iteration215: Tensor(data=0.6752151102667995, grad=0.0)\n",
            "loss in iteration216: Tensor(data=0.670742234613889, grad=0.0)\n",
            "loss in iteration217: Tensor(data=0.6662733932329812, grad=0.0)\n",
            "loss in iteration218: Tensor(data=0.6618089696117606, grad=0.0)\n",
            "loss in iteration219: Tensor(data=0.6573493500154003, grad=0.0)\n",
            "loss in iteration220: Tensor(data=0.6528949233490007, grad=0.0)\n",
            "loss in iteration221: Tensor(data=0.6484460810153084, grad=0.0)\n",
            "loss in iteration222: Tensor(data=0.6440032167677646, grad=0.0)\n",
            "loss in iteration223: Tensor(data=0.6395667265589327, grad=0.0)\n",
            "loss in iteration224: Tensor(data=0.6351370083843779, grad=0.0)\n",
            "loss in iteration225: Tensor(data=0.6307144621220641, grad=0.0)\n",
            "loss in iteration226: Tensor(data=0.6262994893673532, grad=0.0)\n",
            "loss in iteration227: Tensor(data=0.6218924932636986, grad=0.0)\n",
            "loss in iteration228: Tensor(data=0.6174938783291338, grad=0.0)\n",
            "loss in iteration229: Tensor(data=0.6131040502786667, grad=0.0)\n",
            "loss in iteration230: Tensor(data=0.6087234158427004, grad=0.0)\n",
            "loss in iteration231: Tensor(data=0.604352382581608, grad=0.0)\n",
            "loss in iteration232: Tensor(data=0.5999913586966011, grad=0.0)\n",
            "loss in iteration233: Tensor(data=0.5956407528370441, grad=0.0)\n",
            "loss in iteration234: Tensor(data=0.5913009739043696, grad=0.0)\n",
            "loss in iteration235: Tensor(data=0.5869724308527619, grad=0.0)\n",
            "loss in iteration236: Tensor(data=0.5826555324867895, grad=0.0)\n",
            "loss in iteration237: Tensor(data=0.5783506872561692, grad=0.0)\n",
            "loss in iteration238: Tensor(data=0.5740583030478577, grad=0.0)\n",
            "loss in iteration239: Tensor(data=0.5697787869756792, grad=0.0)\n",
            "loss in iteration240: Tensor(data=0.5655125451676942, grad=0.0)\n",
            "loss in iteration241: Tensor(data=0.5612599825515387, grad=0.0)\n",
            "loss in iteration242: Tensor(data=0.5570215026379568, grad=0.0)\n",
            "loss in iteration243: Tensor(data=0.5527975073027671, grad=0.0)\n",
            "loss in iteration244: Tensor(data=0.5485883965675041, grad=0.0)\n",
            "loss in iteration245: Tensor(data=0.5443945683789929, grad=0.0)\n",
            "loss in iteration246: Tensor(data=0.5402164183881032, grad=0.0)\n",
            "loss in iteration247: Tensor(data=0.5360543397279615, grad=0.0)\n",
            "loss in iteration248: Tensor(data=0.5319087227918746, grad=0.0)\n",
            "loss in iteration249: Tensor(data=0.5277799550112563, grad=0.0)\n",
            "loss in iteration250: Tensor(data=0.5236684206338211, grad=0.0)\n",
            "loss in iteration251: Tensor(data=0.5195745005023419, grad=0.0)\n",
            "loss in iteration252: Tensor(data=0.5154985718342471, grad=0.0)\n",
            "loss in iteration253: Tensor(data=0.5114410080023563, grad=0.0)\n",
            "loss in iteration254: Tensor(data=0.5074021783170402, grad=0.0)\n",
            "loss in iteration255: Tensor(data=0.5033824478101034, grad=0.0)\n",
            "loss in iteration256: Tensor(data=0.49938217702067983, grad=0.0)\n",
            "loss in iteration257: Tensor(data=0.4954017217834414, grad=0.0)\n",
            "loss in iteration258: Tensor(data=0.4914414330194096, grad=0.0)\n",
            "loss in iteration259: Tensor(data=0.48750165652966576, grad=0.0)\n",
            "loss in iteration260: Tensor(data=0.4835827327922527, grad=0.0)\n",
            "loss in iteration261: Tensor(data=0.47968499676255355, grad=0.0)\n",
            "loss in iteration262: Tensor(data=0.4758087776774387, grad=0.0)\n",
            "loss in iteration263: Tensor(data=0.4719543988634546, grad=0.0)\n",
            "loss in iteration264: Tensor(data=0.4681221775493446, grad=0.0)\n",
            "loss in iteration265: Tensor(data=0.46431242468315786, grad=0.0)\n",
            "loss in iteration266: Tensor(data=0.46052544475422497, grad=0.0)\n",
            "loss in iteration267: Tensor(data=0.4567615356202524, grad=0.0)\n",
            "loss in iteration268: Tensor(data=0.4530209883397896, grad=0.0)\n",
            "loss in iteration269: Tensor(data=0.4493040870103125, grad=0.0)\n",
            "loss in iteration270: Tensor(data=0.44561110861215286, grad=0.0)\n",
            "loss in iteration271: Tensor(data=0.44194232285850826, grad=0.0)\n",
            "loss in iteration272: Tensor(data=0.43829799205173653, grad=0.0)\n",
            "loss in iteration273: Tensor(data=0.43467837094614803, grad=0.0)\n",
            "loss in iteration274: Tensor(data=0.4310837066174836, grad=0.0)\n",
            "loss in iteration275: Tensor(data=0.42751423833926305, grad=0.0)\n",
            "loss in iteration276: Tensor(data=0.4239701974661711, grad=0.0)\n",
            "loss in iteration277: Tensor(data=0.4204518073246375, grad=0.0)\n",
            "loss in iteration278: Tensor(data=0.41695928311076036, grad=0.0)\n",
            "loss in iteration279: Tensor(data=0.41349283179569396, grad=0.0)\n",
            "loss in iteration280: Tensor(data=0.41005265203862745, grad=0.0)\n",
            "loss in iteration281: Tensor(data=0.40663893410745, grad=0.0)\n",
            "loss in iteration282: Tensor(data=0.40325185980719475, grad=0.0)\n",
            "loss in iteration283: Tensor(data=0.39989160241633326, grad=0.0)\n",
            "loss in iteration284: Tensor(data=0.39655832663098306, grad=0.0)\n",
            "loss in iteration285: Tensor(data=0.3932521885170688, grad=0.0)\n",
            "loss in iteration286: Tensor(data=0.3899733354704711, grad=0.0)\n",
            "loss in iteration287: Tensor(data=0.3867219061851753, grad=0.0)\n",
            "loss in iteration288: Tensor(data=0.3834980306294223, grad=0.0)\n",
            "loss in iteration289: Tensor(data=0.3803018300298462, grad=0.0)\n",
            "loss in iteration290: Tensor(data=0.37713341686356916, grad=0.0)\n",
            "loss in iteration291: Tensor(data=0.3739928948582139, grad=0.0)\n",
            "loss in iteration292: Tensor(data=0.3708803589997695, grad=0.0)\n",
            "loss in iteration293: Tensor(data=0.3677958955482488, grad=0.0)\n",
            "loss in iteration294: Tensor(data=0.36473958206103946, grad=0.0)\n",
            "loss in iteration295: Tensor(data=0.36171148742386416, grad=0.0)\n",
            "loss in iteration296: Tensor(data=0.358711671889228, grad=0.0)\n",
            "loss in iteration297: Tensor(data=0.35574018712223193, grad=0.0)\n",
            "loss in iteration298: Tensor(data=0.3527970762536207, grad=0.0)\n",
            "loss in iteration299: Tensor(data=0.34988237393990945, grad=0.0)\n",
            "loss in iteration300: Tensor(data=0.3469961064304358, grad=0.0)\n",
            "loss in iteration301: Tensor(data=0.3441382916411673, grad=0.0)\n",
            "loss in iteration302: Tensor(data=0.34130893923508127, grad=0.0)\n",
            "loss in iteration303: Tensor(data=0.3385080507089305, grad=0.0)\n",
            "loss in iteration304: Tensor(data=0.33573561948619646, grad=0.0)\n",
            "loss in iteration305: Tensor(data=0.33299163101602197, grad=0.0)\n",
            "loss in iteration306: Tensor(data=0.3302760628779113, grad=0.0)\n",
            "loss in iteration307: Tensor(data=0.3275888848919741, grad=0.0)\n",
            "loss in iteration308: Tensor(data=0.3249300592344887, grad=0.0)\n",
            "loss in iteration309: Tensor(data=0.32229954055854715, grad=0.0)\n",
            "loss in iteration310: Tensor(data=0.31969727611954873, grad=0.0)\n",
            "loss in iteration311: Tensor(data=0.31712320590529497, grad=0.0)\n",
            "loss in iteration312: Tensor(data=0.3145772627704399, grad=0.0)\n",
            "loss in iteration313: Tensor(data=0.3120593725750506, grad=0.0)\n",
            "loss in iteration314: Tensor(data=0.30956945432701954, grad=0.0)\n",
            "loss in iteration315: Tensor(data=0.30710742032807836, grad=0.0)\n",
            "loss in iteration316: Tensor(data=0.30467317632315816, grad=0.0)\n",
            "loss in iteration317: Tensor(data=0.30226662165283963, grad=0.0)\n",
            "loss in iteration318: Tensor(data=0.29988764940863805, grad=0.0)\n",
            "loss in iteration319: Tensor(data=0.2975361465908678, grad=0.0)\n",
            "loss in iteration320: Tensor(data=0.29521199426883377, grad=0.0)\n",
            "loss in iteration321: Tensor(data=0.2929150677430954, grad=0.0)\n",
            "loss in iteration322: Tensor(data=0.2906452367095604, grad=0.0)\n",
            "loss in iteration323: Tensor(data=0.28840236542515035, grad=0.0)\n",
            "loss in iteration324: Tensor(data=0.28618631287480656, grad=0.0)\n",
            "loss in iteration325: Tensor(data=0.28399693293958916, grad=0.0)\n",
            "loss in iteration326: Tensor(data=0.28183407456563686, grad=0.0)\n",
            "loss in iteration327: Tensor(data=0.27969758193375677, grad=0.0)\n",
            "loss in iteration328: Tensor(data=0.2775872946294174, grad=0.0)\n",
            "loss in iteration329: Tensor(data=0.27550304781292634, grad=0.0)\n",
            "loss in iteration330: Tensor(data=0.27344467238957665, grad=0.0)\n",
            "loss in iteration331: Tensor(data=0.2714119951795556, grad=0.0)\n",
            "loss in iteration332: Tensor(data=0.2694048390874102, grad=0.0)\n",
            "loss in iteration333: Tensor(data=0.2674230232708773, grad=0.0)\n",
            "loss in iteration334: Tensor(data=0.26546636330888845, grad=0.0)\n",
            "loss in iteration335: Tensor(data=0.2635346713685656, grad=0.0)\n",
            "loss in iteration336: Tensor(data=0.2616277563710378, grad=0.0)\n",
            "loss in iteration337: Tensor(data=0.25974542415590635, grad=0.0)\n",
            "loss in iteration338: Tensor(data=0.25788747764420067, grad=0.0)\n",
            "loss in iteration339: Tensor(data=0.2560537169996747, grad=0.0)\n",
            "loss in iteration340: Tensor(data=0.25424393978829385, grad=0.0)\n",
            "loss in iteration341: Tensor(data=0.2524579411357804, grad=0.0)\n",
            "loss in iteration342: Tensor(data=0.25069551388308525, grad=0.0)\n",
            "loss in iteration343: Tensor(data=0.24895644873966236, grad=0.0)\n",
            "loss in iteration344: Tensor(data=0.2472405344344363, grad=0.0)\n",
            "loss in iteration345: Tensor(data=0.24554755786435092, grad=0.0)\n",
            "loss in iteration346: Tensor(data=0.2438773042404039, grad=0.0)\n",
            "loss in iteration347: Tensor(data=0.24222955723107267, grad=0.0)\n",
            "loss in iteration348: Tensor(data=0.24060409910304859, grad=0.0)\n",
            "loss in iteration349: Tensor(data=0.23900071085920152, grad=0.0)\n",
            "loss in iteration350: Tensor(data=0.23741917237370533, grad=0.0)\n",
            "loss in iteration351: Tensor(data=0.23585926252426073, grad=0.0)\n",
            "loss in iteration352: Tensor(data=0.23432075932135749, grad=0.0)\n",
            "loss in iteration353: Tensor(data=0.2328034400345312, grad=0.0)\n",
            "loss in iteration354: Tensor(data=0.23130708131556457, grad=0.0)\n",
            "loss in iteration355: Tensor(data=0.22983145931860255, grad=0.0)\n",
            "loss in iteration356: Tensor(data=0.22837634981714555, grad=0.0)\n",
            "loss in iteration357: Tensor(data=0.22694152831790138, grad=0.0)\n",
            "loss in iteration358: Tensor(data=0.2255267701714699, grad=0.0)\n",
            "loss in iteration359: Tensor(data=0.22413185067985458, grad=0.0)\n",
            "loss in iteration360: Tensor(data=0.22275654520078508, grad=0.0)\n",
            "loss in iteration361: Tensor(data=0.22140062924885331, grad=0.0)\n",
            "loss in iteration362: Tensor(data=0.2200638785934629, grad=0.0)\n",
            "loss in iteration363: Tensor(data=0.21874606935359647, grad=0.0)\n",
            "loss in iteration364: Tensor(data=0.21744697808941493, grad=0.0)\n",
            "loss in iteration365: Tensor(data=0.2161663818907013, grad=0.0)\n",
            "loss in iteration366: Tensor(data=0.21490405846216948, grad=0.0)\n",
            "loss in iteration367: Tensor(data=0.21365978620565823, grad=0.0)\n",
            "loss in iteration368: Tensor(data=0.2124333442992423, grad=0.0)\n",
            "loss in iteration369: Tensor(data=0.21122451277328366, grad=0.0)\n",
            "loss in iteration370: Tensor(data=0.21003307258346013, grad=0.0)\n",
            "loss in iteration371: Tensor(data=0.2088588056808064, grad=0.0)\n",
            "loss in iteration372: Tensor(data=0.20770149507880534, grad=0.0)\n",
            "loss in iteration373: Tensor(data=0.20656092491757014, grad=0.0)\n",
            "loss in iteration374: Tensor(data=0.2054368805251631, grad=0.0)\n",
            "loss in iteration375: Tensor(data=0.20432914847609446, grad=0.0)\n",
            "loss in iteration376: Tensor(data=0.2032375166470483, grad=0.0)\n",
            "loss in iteration377: Tensor(data=0.2021617742698884, grad=0.0)\n",
            "loss in iteration378: Tensor(data=0.20110171198199026, grad=0.0)\n",
            "loss in iteration379: Tensor(data=0.20005712187395577, grad=0.0)\n",
            "loss in iteration380: Tensor(data=0.1990277975347607, grad=0.0)\n",
            "loss in iteration381: Tensor(data=0.19801353409439348, grad=0.0)\n",
            "loss in iteration382: Tensor(data=0.19701412826403686, grad=0.0)\n",
            "loss in iteration383: Tensor(data=0.19602937837385234, grad=0.0)\n",
            "loss in iteration384: Tensor(data=0.19505908440842432, grad=0.0)\n",
            "loss in iteration385: Tensor(data=0.19410304803991782, grad=0.0)\n",
            "loss in iteration386: Tensor(data=0.19316107265901394, grad=0.0)\n",
            "loss in iteration387: Tensor(data=0.19223296340367713, grad=0.0)\n",
            "loss in iteration388: Tensor(data=0.1913185271858146, grad=0.0)\n",
            "loss in iteration389: Tensor(data=0.1904175727158858, grad=0.0)\n",
            "loss in iteration390: Tensor(data=0.18952991052552307, grad=0.0)\n",
            "loss in iteration391: Tensor(data=0.18865535298821784, grad=0.0)\n",
            "loss in iteration392: Tensor(data=0.18779371433813538, grad=0.0)\n",
            "loss in iteration393: Tensor(data=0.18694481068711197, grad=0.0)\n",
            "loss in iteration394: Tensor(data=0.18610846003989642, grad=0.0)\n",
            "loss in iteration395: Tensor(data=0.18528448230768899, grad=0.0)\n",
            "loss in iteration396: Tensor(data=0.18447269932003743, grad=0.0)\n",
            "loss in iteration397: Tensor(data=0.18367293483514466, grad=0.0)\n",
            "loss in iteration398: Tensor(data=0.1828850145486453, grad=0.0)\n",
            "loss in iteration399: Tensor(data=0.1821087661009031, grad=0.0)\n",
            "loss in iteration400: Tensor(data=0.18134401908288558, grad=0.0)\n",
            "loss in iteration401: Tensor(data=0.1805906050406681, grad=0.0)\n",
            "loss in iteration402: Tensor(data=0.179848357478621, grad=0.0)\n",
            "loss in iteration403: Tensor(data=0.1791171118613275, grad=0.0)\n",
            "loss in iteration404: Tensor(data=0.1783967056142887, grad=0.0)\n",
            "loss in iteration405: Tensor(data=0.17768697812346107, grad=0.0)\n",
            "loss in iteration406: Tensor(data=0.1769877707336746, grad=0.0)\n",
            "loss in iteration407: Tensor(data=0.17629892674598363, grad=0.0)\n",
            "loss in iteration408: Tensor(data=0.17562029141399232, grad=0.0)\n",
            "loss in iteration409: Tensor(data=0.17495171193920267, grad=0.0)\n",
            "loss in iteration410: Tensor(data=0.17429303746542962, grad=0.0)\n",
            "loss in iteration411: Tensor(data=0.17364411907232594, grad=0.0)\n",
            "loss in iteration412: Tensor(data=0.17300480976805982, grad=0.0)\n",
            "loss in iteration413: Tensor(data=0.1723749644811866, grad=0.0)\n",
            "loss in iteration414: Tensor(data=0.1717544400517545, grad=0.0)\n",
            "loss in iteration415: Tensor(data=0.17114309522168394, grad=0.0)\n",
            "loss in iteration416: Tensor(data=0.1705407906244587, grad=0.0)\n",
            "loss in iteration417: Tensor(data=0.16994738877416496, grad=0.0)\n",
            "loss in iteration418: Tensor(data=0.16936275405391654, grad=0.0)\n",
            "loss in iteration419: Tensor(data=0.16878675270369783, grad=0.0)\n",
            "loss in iteration420: Tensor(data=0.16821925280766215, grad=0.0)\n",
            "loss in iteration421: Tensor(data=0.16766012428091487, grad=0.0)\n",
            "loss in iteration422: Tensor(data=0.16710923885581597, grad=0.0)\n",
            "loss in iteration423: Tensor(data=0.16656647006783062, grad=0.0)\n",
            "loss in iteration424: Tensor(data=0.16603169324095912, grad=0.0)\n",
            "loss in iteration425: Tensor(data=0.1655047854727742, grad=0.0)\n",
            "loss in iteration426: Tensor(data=0.16498562561909366, grad=0.0)\n",
            "loss in iteration427: Tensor(data=0.16447409427831544, grad=0.0)\n",
            "loss in iteration428: Tensor(data=0.1639700737754403, grad=0.0)\n",
            "loss in iteration429: Tensor(data=0.1634734481458078, grad=0.0)\n",
            "loss in iteration430: Tensor(data=0.16298410311857028, grad=0.0)\n",
            "loss in iteration431: Tensor(data=0.16250192609992534, grad=0.0)\n",
            "loss in iteration432: Tensor(data=0.16202680615613257, grad=0.0)\n",
            "loss in iteration433: Tensor(data=0.16155863399633355, grad=0.0)\n",
            "loss in iteration434: Tensor(data=0.16109730195519578, grad=0.0)\n",
            "loss in iteration435: Tensor(data=0.16064270397540234, grad=0.0)\n",
            "loss in iteration436: Tensor(data=0.1601947355900039, grad=0.0)\n",
            "loss in iteration437: Tensor(data=0.15975329390465162, grad=0.0)\n",
            "loss in iteration438: Tensor(data=0.15931827757973094, grad=0.0)\n",
            "loss in iteration439: Tensor(data=0.15888958681240825, grad=0.0)\n",
            "loss in iteration440: Tensor(data=0.15846712331861085, grad=0.0)\n",
            "loss in iteration441: Tensor(data=0.15805079031495328, grad=0.0)\n",
            "loss in iteration442: Tensor(data=0.15764049250062404, grad=0.0)\n",
            "loss in iteration443: Tensor(data=0.15723613603924863, grad=0.0)\n",
            "loss in iteration444: Tensor(data=0.1568376285407402, grad=0.0)\n",
            "loss in iteration445: Tensor(data=0.15644487904315074, grad=0.0)\n",
            "loss in iteration446: Tensor(data=0.1560577979945369, grad=0.0)\n",
            "loss in iteration447: Tensor(data=0.15567629723484824, grad=0.0)\n",
            "loss in iteration448: Tensor(data=0.15530028997785184, grad=0.0)\n",
            "loss in iteration449: Tensor(data=0.15492969079310254, grad=0.0)\n",
            "loss in iteration450: Tensor(data=0.15456441558796724, grad=0.0)\n",
            "loss in iteration451: Tensor(data=0.15420438158971556, grad=0.0)\n",
            "loss in iteration452: Tensor(data=0.15384950732768166, grad=0.0)\n",
            "loss in iteration453: Tensor(data=0.15349971261550951, grad=0.0)\n",
            "loss in iteration454: Tensor(data=0.1531549185334861, grad=0.0)\n",
            "loss in iteration455: Tensor(data=0.15281504741097104, grad=0.0)\n",
            "loss in iteration456: Tensor(data=0.15248002280893175, grad=0.0)\n",
            "loss in iteration457: Tensor(data=0.1521497695025853, grad=0.0)\n",
            "loss in iteration458: Tensor(data=0.15182421346415978, grad=0.0)\n",
            "loss in iteration459: Tensor(data=0.15150328184577463, grad=0.0)\n",
            "loss in iteration460: Tensor(data=0.15118690296244983, grad=0.0)\n",
            "loss in iteration461: Tensor(data=0.15087500627524628, grad=0.0)\n",
            "loss in iteration462: Tensor(data=0.1505675223745426, grad=0.0)\n",
            "loss in iteration463: Tensor(data=0.15026438296345399, grad=0.0)\n",
            "loss in iteration464: Tensor(data=0.14996552084139403, grad=0.0)\n",
            "loss in iteration465: Tensor(data=0.1496708698877875, grad=0.0)\n",
            "loss in iteration466: Tensor(data=0.14938036504593205, grad=0.0)\n",
            "loss in iteration467: Tensor(data=0.14909394230701822, grad=0.0)\n",
            "loss in iteration468: Tensor(data=0.14881153869430372, grad=0.0)\n",
            "loss in iteration469: Tensor(data=0.14853309224745123, grad=0.0)\n",
            "loss in iteration470: Tensor(data=0.14825854200702626, grad=0.0)\n",
            "loss in iteration471: Tensor(data=0.14798782799916144, grad=0.0)\n",
            "loss in iteration472: Tensor(data=0.14772089122038615, grad=0.0)\n",
            "loss in iteration473: Tensor(data=0.14745767362262516, grad=0.0)\n",
            "loss in iteration474: Tensor(data=0.14719811809836642, grad=0.0)\n",
            "loss in iteration475: Tensor(data=0.14694216846599956, grad=0.0)\n",
            "loss in iteration476: Tensor(data=0.1466897694553264, grad=0.0)\n",
            "loss in iteration477: Tensor(data=0.1464408666932445, grad=0.0)\n",
            "loss in iteration478: Tensor(data=0.14619540668960315, grad=0.0)\n",
            "loss in iteration479: Tensor(data=0.14595333682323414, grad=0.0)\n",
            "loss in iteration480: Tensor(data=0.1457146053281568, grad=0.0)\n",
            "loss in iteration481: Tensor(data=0.14547916127995655, grad=0.0)\n",
            "loss in iteration482: Tensor(data=0.14524695458233966, grad=0.0)\n",
            "loss in iteration483: Tensor(data=0.1450179359538613, grad=0.0)\n",
            "loss in iteration484: Tensor(data=0.14479205691482835, grad=0.0)\n",
            "loss in iteration485: Tensor(data=0.1445692697743766, grad=0.0)\n",
            "loss in iteration486: Tensor(data=0.14434952761772127, grad=0.0)\n",
            "loss in iteration487: Tensor(data=0.1441327842935817, grad=0.0)\n",
            "loss in iteration488: Tensor(data=0.1439189944017771, grad=0.0)\n",
            "loss in iteration489: Tensor(data=0.14370811328099548, grad=0.0)\n",
            "loss in iteration490: Tensor(data=0.14350009699673405, grad=0.0)\n",
            "loss in iteration491: Tensor(data=0.14329490232940806, grad=0.0)\n",
            "loss in iteration492: Tensor(data=0.14309248676263184, grad=0.0)\n",
            "loss in iteration493: Tensor(data=0.14289280847166538, grad=0.0)\n",
            "loss in iteration494: Tensor(data=0.14269582631203043, grad=0.0)\n",
            "loss in iteration495: Tensor(data=0.14250149980829127, grad=0.0)\n",
            "loss in iteration496: Tensor(data=0.14230978914300146, grad=0.0)\n",
            "loss in iteration497: Tensor(data=0.14212065514581373, grad=0.0)\n",
            "loss in iteration498: Tensor(data=0.14193405928275196, grad=0.0)\n",
            "loss in iteration499: Tensor(data=0.14174996364564577, grad=0.0)\n",
            "loss in iteration500: Tensor(data=0.14156833094172258, grad=0.0)\n",
            "loss in iteration501: Tensor(data=0.1413891244833597, grad=0.0)\n",
            "loss in iteration502: Tensor(data=0.14121230817799185, grad=0.0)\n",
            "loss in iteration503: Tensor(data=0.14103784651817566, grad=0.0)\n",
            "loss in iteration504: Tensor(data=0.14086570457180522, grad=0.0)\n",
            "loss in iteration505: Tensor(data=0.1406958479724824, grad=0.0)\n",
            "loss in iteration506: Tensor(data=0.14052824291003632, grad=0.0)\n",
            "loss in iteration507: Tensor(data=0.14036285612119195, grad=0.0)\n",
            "loss in iteration508: Tensor(data=0.14019965488038627, grad=0.0)\n",
            "loss in iteration509: Tensor(data=0.1400386069907296, grad=0.0)\n",
            "loss in iteration510: Tensor(data=0.13987968077511143, grad=0.0)\n",
            "loss in iteration511: Tensor(data=0.1397228450674484, grad=0.0)\n",
            "loss in iteration512: Tensor(data=0.13956806920407272, grad=0.0)\n",
            "loss in iteration513: Tensor(data=0.13941532301525922, grad=0.0)\n",
            "loss in iteration514: Tensor(data=0.13926457681689053, grad=0.0)\n",
            "loss in iteration515: Tensor(data=0.13911580140225682, grad=0.0)\n",
            "loss in iteration516: Tensor(data=0.13896896803398917, grad=0.0)\n",
            "loss in iteration517: Tensor(data=0.13882404843612647, grad=0.0)\n",
            "loss in iteration518: Tensor(data=0.1386810147863105, grad=0.0)\n",
            "loss in iteration519: Tensor(data=0.13853983970811098, grad=0.0)\n",
            "loss in iteration520: Tensor(data=0.13840049626347725, grad=0.0)\n",
            "loss in iteration521: Tensor(data=0.13826295794531498, grad=0.0)\n",
            "loss in iteration522: Tensor(data=0.13812719867018558, grad=0.0)\n",
            "loss in iteration523: Tensor(data=0.137993192771129, grad=0.0)\n",
            "loss in iteration524: Tensor(data=0.13786091499060493, grad=0.0)\n",
            "loss in iteration525: Tensor(data=0.13773034047355265, grad=0.0)\n",
            "loss in iteration526: Tensor(data=0.13760144476056818, grad=0.0)\n",
            "loss in iteration527: Tensor(data=0.13747420378119546, grad=0.0)\n",
            "loss in iteration528: Tensor(data=0.13734859384733147, grad=0.0)\n",
            "loss in iteration529: Tensor(data=0.13722459164674247, grad=0.0)\n",
            "loss in iteration530: Tensor(data=0.1371021742366904, grad=0.0)\n",
            "loss in iteration531: Tensor(data=0.13698131903766728, grad=0.0)\n",
            "loss in iteration532: Tensor(data=0.13686200382723682, grad=0.0)\n",
            "loss in iteration533: Tensor(data=0.13674420673398008, grad=0.0)\n",
            "loss in iteration534: Tensor(data=0.1366279062315465, grad=0.0)\n",
            "loss in iteration535: Tensor(data=0.13651308113280378, grad=0.0)\n",
            "loss in iteration536: Tensor(data=0.136399710584091, grad=0.0)\n",
            "loss in iteration537: Tensor(data=0.1362877740595689, grad=0.0)\n",
            "loss in iteration538: Tensor(data=0.13617725135566722, grad=0.0)\n",
            "loss in iteration539: Tensor(data=0.13606812258562836, grad=0.0)\n",
            "loss in iteration540: Tensor(data=0.13596036817414522, grad=0.0)\n",
            "loss in iteration541: Tensor(data=0.13585396885209047, grad=0.0)\n",
            "loss in iteration542: Tensor(data=0.13574890565133865, grad=0.0)\n",
            "loss in iteration543: Tensor(data=0.13564515989967654, grad=0.0)\n",
            "loss in iteration544: Tensor(data=0.13554271321580263, grad=0.0)\n",
            "loss in iteration545: Tensor(data=0.1354415475044129, grad=0.0)\n",
            "loss in iteration546: Tensor(data=0.1353416449513721, grad=0.0)\n",
            "loss in iteration547: Tensor(data=0.13524298801896908, grad=0.0)\n",
            "loss in iteration548: Tensor(data=0.13514555944125484, grad=0.0)\n",
            "loss in iteration549: Tensor(data=0.13504934221946152, grad=0.0)\n",
            "loss in iteration550: Tensor(data=0.13495431961750104, grad=0.0)\n",
            "loss in iteration551: Tensor(data=0.1348604751575434, grad=0.0)\n",
            "loss in iteration552: Tensor(data=0.13476779261567087, grad=0.0)\n",
            "loss in iteration553: Tensor(data=0.13467625601760883, grad=0.0)\n",
            "loss in iteration554: Tensor(data=0.13458584963453124, grad=0.0)\n",
            "loss in iteration555: Tensor(data=0.1344965579789394, grad=0.0)\n",
            "loss in iteration556: Tensor(data=0.13440836580061294, grad=0.0)\n",
            "loss in iteration557: Tensor(data=0.13432125808263148, grad=0.0)\n",
            "loss in iteration558: Tensor(data=0.13423522003746685, grad=0.0)\n",
            "loss in iteration559: Tensor(data=0.13415023710314214, grad=0.0)\n",
            "loss in iteration560: Tensor(data=0.13406629493946068, grad=0.0)\n",
            "loss in iteration561: Tensor(data=0.13398337942429814, grad=0.0)\n",
            "loss in iteration562: Tensor(data=0.13390147664996271, grad=0.0)\n",
            "loss in iteration563: Tensor(data=0.1338205729196167, grad=0.0)\n",
            "loss in iteration564: Tensor(data=0.13374065474376307, grad=0.0)\n",
            "loss in iteration565: Tensor(data=0.13366170883679146, grad=0.0)\n",
            "loss in iteration566: Tensor(data=0.13358372211358752, grad=0.0)\n",
            "loss in iteration567: Tensor(data=0.13350668168619945, grad=0.0)\n",
            "loss in iteration568: Tensor(data=0.1334305748605646, grad=0.0)\n",
            "loss in iteration569: Tensor(data=0.13335538913329278, grad=0.0)\n",
            "loss in iteration570: Tensor(data=0.133281112188507, grad=0.0)\n",
            "loss in iteration571: Tensor(data=0.13320773189473858, grad=0.0)\n",
            "loss in iteration572: Tensor(data=0.13313523630187785, grad=0.0)\n",
            "loss in iteration573: Tensor(data=0.1330636136381778, grad=0.0)\n",
            "loss in iteration574: Tensor(data=0.13299285230731114, grad=0.0)\n",
            "loss in iteration575: Tensor(data=0.13292294088547776, grad=0.0)\n",
            "loss in iteration576: Tensor(data=0.13285386811856478, grad=0.0)\n",
            "loss in iteration577: Tensor(data=0.13278562291935458, grad=0.0)\n",
            "loss in iteration578: Tensor(data=0.13271819436478374, grad=0.0)\n",
            "loss in iteration579: Tensor(data=0.1326515716932487, grad=0.0)\n",
            "loss in iteration580: Tensor(data=0.13258574430195916, grad=0.0)\n",
            "loss in iteration581: Tensor(data=0.13252070174433844, grad=0.0)\n",
            "loss in iteration582: Tensor(data=0.13245643372746863, grad=0.0)\n",
            "loss in iteration583: Tensor(data=0.13239293010958103, grad=0.0)\n",
            "loss in iteration584: Tensor(data=0.13233018089759055, grad=0.0)\n",
            "loss in iteration585: Tensor(data=0.13226817624467346, grad=0.0)\n",
            "loss in iteration586: Tensor(data=0.13220690644788707, grad=0.0)\n",
            "loss in iteration587: Tensor(data=0.1321463619458317, grad=0.0)\n",
            "loss in iteration588: Tensor(data=0.13208653331635303, grad=0.0)\n",
            "loss in iteration589: Tensor(data=0.1320274112742855, grad=0.0)\n",
            "loss in iteration590: Tensor(data=0.13196898666923368, grad=0.0)\n",
            "loss in iteration591: Tensor(data=0.1319112504833943, grad=0.0)\n",
            "loss in iteration592: Tensor(data=0.13185419382941485, grad=0.0)\n",
            "loss in iteration593: Tensor(data=0.13179780794829019, grad=0.0)\n",
            "loss in iteration594: Tensor(data=0.13174208420729563, grad=0.0)\n",
            "loss in iteration595: Tensor(data=0.13168701409795666, grad=0.0)\n",
            "loss in iteration596: Tensor(data=0.13163258923405313, grad=0.0)\n",
            "loss in iteration597: Tensor(data=0.1315788013496589, grad=0.0)\n",
            "loss in iteration598: Tensor(data=0.13152564229721528, grad=0.0)\n",
            "loss in iteration599: Tensor(data=0.1314731040456382, grad=0.0)\n",
            "loss in iteration600: Tensor(data=0.13142117867845807, grad=0.0)\n",
            "loss in iteration601: Tensor(data=0.13136985839199208, grad=0.0)\n",
            "loss in iteration602: Tensor(data=0.13131913549354832, grad=0.0)\n",
            "loss in iteration603: Tensor(data=0.1312690023996603, grad=0.0)\n",
            "loss in iteration604: Tensor(data=0.13121945163435383, grad=0.0)\n",
            "loss in iteration605: Tensor(data=0.13117047582744154, grad=0.0)\n",
            "loss in iteration606: Tensor(data=0.13112206771284887, grad=0.0)\n",
            "loss in iteration607: Tensor(data=0.13107422012696823, grad=0.0)\n",
            "loss in iteration608: Tensor(data=0.1310269260070414, grad=0.0)\n",
            "loss in iteration609: Tensor(data=0.13098017838957002, grad=0.0)\n",
            "loss in iteration610: Tensor(data=0.13093397040875374, grad=0.0)\n",
            "loss in iteration611: Tensor(data=0.13088829529495496, grad=0.0)\n",
            "loss in iteration612: Tensor(data=0.13084314637319047, grad=0.0)\n",
            "loss in iteration613: Tensor(data=0.13079851706164777, grad=0.0)\n",
            "loss in iteration614: Tensor(data=0.13075440087022888, grad=0.0)\n",
            "loss in iteration615: Tensor(data=0.13071079139911734, grad=0.0)\n",
            "loss in iteration616: Tensor(data=0.13066768233737083, grad=0.0)\n",
            "loss in iteration617: Tensor(data=0.13062506746153718, grad=0.0)\n",
            "loss in iteration618: Tensor(data=0.13058294063429476, grad=0.0)\n",
            "loss in iteration619: Tensor(data=0.13054129580311594, grad=0.0)\n",
            "loss in iteration620: Tensor(data=0.13050012699895275, grad=0.0)\n",
            "loss in iteration621: Tensor(data=0.13045942833494573, grad=0.0)\n",
            "loss in iteration622: Tensor(data=0.13041919400515456, grad=0.0)\n",
            "loss in iteration623: Tensor(data=0.13037941828331004, grad=0.0)\n",
            "loss in iteration624: Tensor(data=0.1303400955215876, grad=0.0)\n",
            "loss in iteration625: Tensor(data=0.13030122014940163, grad=0.0)\n",
            "loss in iteration626: Tensor(data=0.1302627866722199, grad=0.0)\n",
            "loss in iteration627: Tensor(data=0.13022478967039863, grad=0.0)\n",
            "loss in iteration628: Tensor(data=0.13018722379803674, grad=0.0)\n",
            "loss in iteration629: Tensor(data=0.13015008378184995, grad=0.0)\n",
            "loss in iteration630: Tensor(data=0.1301133644200635, grad=0.0)\n",
            "loss in iteration631: Tensor(data=0.1300770605813239, grad=0.0)\n",
            "loss in iteration632: Tensor(data=0.1300411672036285, grad=0.0)\n",
            "loss in iteration633: Tensor(data=0.13000567929327414, grad=0.0)\n",
            "loss in iteration634: Tensor(data=0.12997059192382157, grad=0.0)\n",
            "loss in iteration635: Tensor(data=0.12993590023507967, grad=0.0)\n",
            "loss in iteration636: Tensor(data=0.12990159943210464, grad=0.0)\n",
            "loss in iteration637: Tensor(data=0.12986768478421712, grad=0.0)\n",
            "loss in iteration638: Tensor(data=0.12983415162403533, grad=0.0)\n",
            "loss in iteration639: Tensor(data=0.1298009953465245, grad=0.0)\n",
            "loss in iteration640: Tensor(data=0.12976821140806186, grad=0.0)\n",
            "loss in iteration641: Tensor(data=0.12973579532551766, grad=0.0)\n",
            "loss in iteration642: Tensor(data=0.12970374267535123, grad=0.0)\n",
            "loss in iteration643: Tensor(data=0.12967204909272195, grad=0.0)\n",
            "loss in iteration644: Tensor(data=0.1296407102706155, grad=0.0)\n",
            "loss in iteration645: Tensor(data=0.1296097219589836, grad=0.0)\n",
            "loss in iteration646: Tensor(data=0.1295790799638991, grad=0.0)\n",
            "loss in iteration647: Tensor(data=0.12954878014672438, grad=0.0)\n",
            "loss in iteration648: Tensor(data=0.12951881842329346, grad=0.0)\n",
            "loss in iteration649: Tensor(data=0.12948919076310783, grad=0.0)\n",
            "loss in iteration650: Tensor(data=0.12945989318854603, grad=0.0)\n",
            "loss in iteration651: Tensor(data=0.12943092177408427, grad=0.0)\n",
            "loss in iteration652: Tensor(data=0.12940227264553275, grad=0.0)\n",
            "loss in iteration653: Tensor(data=0.12937394197928195, grad=0.0)\n",
            "loss in iteration654: Tensor(data=0.12934592600156258, grad=0.0)\n",
            "loss in iteration655: Tensor(data=0.12931822098771728, grad=0.0)\n",
            "loss in iteration656: Tensor(data=0.12929082326148442, grad=0.0)\n",
            "loss in iteration657: Tensor(data=0.12926372919429296, grad=0.0)\n",
            "loss in iteration658: Tensor(data=0.1292369352045695, grad=0.0)\n",
            "loss in iteration659: Tensor(data=0.1292104377570564, grad=0.0)\n",
            "loss in iteration660: Tensor(data=0.12918423336214066, grad=0.0)\n",
            "loss in iteration661: Tensor(data=0.12915831857519383, grad=0.0)\n",
            "loss in iteration662: Tensor(data=0.129132689995923, grad=0.0)\n",
            "loss in iteration663: Tensor(data=0.12910734426773135, grad=0.0)\n",
            "loss in iteration664: Tensor(data=0.12908227807709016, grad=0.0)\n",
            "loss in iteration665: Tensor(data=0.1290574881529199, grad=0.0)\n",
            "loss in iteration666: Tensor(data=0.12903297126598207, grad=0.0)\n",
            "loss in iteration667: Tensor(data=0.12900872422828016, grad=0.0)\n",
            "loss in iteration668: Tensor(data=0.12898474389247094, grad=0.0)\n",
            "loss in iteration669: Tensor(data=0.12896102715128416, grad=0.0)\n",
            "loss in iteration670: Tensor(data=0.12893757093695254, grad=0.0)\n",
            "loss in iteration671: Tensor(data=0.12891437222065044, grad=0.0)\n",
            "loss in iteration672: Tensor(data=0.12889142801194098, grad=0.0)\n",
            "loss in iteration673: Tensor(data=0.12886873535823315, grad=0.0)\n",
            "loss in iteration674: Tensor(data=0.12884629134424616, grad=0.0)\n",
            "loss in iteration675: Tensor(data=0.1288240930914834, grad=0.0)\n",
            "loss in iteration676: Tensor(data=0.128802137757714, grad=0.0)\n",
            "loss in iteration677: Tensor(data=0.1287804225364631, grad=0.0)\n",
            "loss in iteration678: Tensor(data=0.12875894465650944, grad=0.0)\n",
            "loss in iteration679: Tensor(data=0.12873770138139223, grad=0.0)\n",
            "loss in iteration680: Tensor(data=0.12871669000892366, grad=0.0)\n",
            "loss in iteration681: Tensor(data=0.12869590787071167, grad=0.0)\n",
            "loss in iteration682: Tensor(data=0.12867535233168764, grad=0.0)\n",
            "loss in iteration683: Tensor(data=0.12865502078964342, grad=0.0)\n",
            "loss in iteration684: Tensor(data=0.12863491067477434, grad=0.0)\n",
            "loss in iteration685: Tensor(data=0.12861501944923034, grad=0.0)\n",
            "loss in iteration686: Tensor(data=0.12859534460667318, grad=0.0)\n",
            "loss in iteration687: Tensor(data=0.1285758836718413, grad=0.0)\n",
            "loss in iteration688: Tensor(data=0.12855663420012056, grad=0.0)\n",
            "loss in iteration689: Tensor(data=0.12853759377712273, grad=0.0)\n",
            "loss in iteration690: Tensor(data=0.1285187600182697, grad=0.0)\n",
            "loss in iteration691: Tensor(data=0.1285001305683843, grad=0.0)\n",
            "loss in iteration692: Tensor(data=0.12848170310128754, grad=0.0)\n",
            "loss in iteration693: Tensor(data=0.12846347531940186, grad=0.0)\n",
            "loss in iteration694: Tensor(data=0.12844544495336083, grad=0.0)\n",
            "loss in iteration695: Tensor(data=0.12842760976162432, grad=0.0)\n",
            "loss in iteration696: Tensor(data=0.12840996753010017, grad=0.0)\n",
            "loss in iteration697: Tensor(data=0.1283925160717712, grad=0.0)\n",
            "loss in iteration698: Tensor(data=0.12837525322632787, grad=0.0)\n",
            "loss in iteration699: Tensor(data=0.12835817685980688, grad=0.0)\n",
            "loss in iteration700: Tensor(data=0.1283412848642351, grad=0.0)\n",
            "loss in iteration701: Tensor(data=0.12832457515727907, grad=0.0)\n",
            "loss in iteration702: Tensor(data=0.12830804568189885, grad=0.0)\n",
            "loss in iteration703: Tensor(data=0.12829169440600946, grad=0.0)\n",
            "loss in iteration704: Tensor(data=0.128275519322144, grad=0.0)\n",
            "loss in iteration705: Tensor(data=0.12825951844712527, grad=0.0)\n",
            "loss in iteration706: Tensor(data=0.12824368982173995, grad=0.0)\n",
            "loss in iteration707: Tensor(data=0.1282280315104188, grad=0.0)\n",
            "loss in iteration708: Tensor(data=0.12821254160092158, grad=0.0)\n",
            "loss in iteration709: Tensor(data=0.1281972182040258, grad=0.0)\n",
            "loss in iteration710: Tensor(data=0.1281820594532218, grad=0.0)\n",
            "loss in iteration711: Tensor(data=0.1281670635044105, grad=0.0)\n",
            "loss in iteration712: Tensor(data=0.12815222853560712, grad=0.0)\n",
            "loss in iteration713: Tensor(data=0.12813755274664862, grad=0.0)\n",
            "loss in iteration714: Tensor(data=0.12812303435890537, grad=0.0)\n",
            "loss in iteration715: Tensor(data=0.1281086716149975, grad=0.0)\n",
            "loss in iteration716: Tensor(data=0.12809446277851547, grad=0.0)\n",
            "loss in iteration717: Tensor(data=0.1280804061337441, grad=0.0)\n",
            "loss in iteration718: Tensor(data=0.1280664999853916, grad=0.0)\n",
            "loss in iteration719: Tensor(data=0.12805274265832195, grad=0.0)\n",
            "loss in iteration720: Tensor(data=0.12803913249729107, grad=0.0)\n",
            "loss in iteration721: Tensor(data=0.12802566786668804, grad=0.0)\n",
            "loss in iteration722: Tensor(data=0.12801234715027807, grad=0.0)\n",
            "loss in iteration723: Tensor(data=0.1279991687509515, grad=0.0)\n",
            "loss in iteration724: Tensor(data=0.12798613109047455, grad=0.0)\n",
            "loss in iteration725: Tensor(data=0.12797323260924517, grad=0.0)\n",
            "loss in iteration726: Tensor(data=0.12796047176605138, grad=0.0)\n",
            "loss in iteration727: Tensor(data=0.12794784703783338, grad=0.0)\n",
            "loss in iteration728: Tensor(data=0.12793535691944985, grad=0.0)\n",
            "loss in iteration729: Tensor(data=0.12792299992344655, grad=0.0)\n",
            "loss in iteration730: Tensor(data=0.12791077457982866, grad=0.0)\n",
            "loss in iteration731: Tensor(data=0.12789867943583694, grad=0.0)\n",
            "loss in iteration732: Tensor(data=0.12788671305572635, grad=0.0)\n",
            "loss in iteration733: Tensor(data=0.12787487402054812, grad=0.0)\n",
            "loss in iteration734: Tensor(data=0.12786316092793498, grad=0.0)\n",
            "loss in iteration735: Tensor(data=0.12785157239188968, grad=0.0)\n",
            "loss in iteration736: Tensor(data=0.12784010704257626, grad=0.0)\n",
            "loss in iteration737: Tensor(data=0.12782876352611378, grad=0.0)\n",
            "loss in iteration738: Tensor(data=0.12781754050437455, grad=0.0)\n",
            "loss in iteration739: Tensor(data=0.12780643665478322, grad=0.0)\n",
            "loss in iteration740: Tensor(data=0.12779545067012055, grad=0.0)\n",
            "loss in iteration741: Tensor(data=0.12778458125832853, grad=0.0)\n",
            "loss in iteration742: Tensor(data=0.12777382714231933, grad=0.0)\n",
            "loss in iteration743: Tensor(data=0.12776318705978595, grad=0.0)\n",
            "loss in iteration744: Tensor(data=0.12775265976301667, grad=0.0)\n",
            "loss in iteration745: Tensor(data=0.12774224401871093, grad=0.0)\n",
            "loss in iteration746: Tensor(data=0.12773193860779888, grad=0.0)\n",
            "loss in iteration747: Tensor(data=0.12772174232526237, grad=0.0)\n",
            "loss in iteration748: Tensor(data=0.12771165397995968, grad=0.0)\n",
            "loss in iteration749: Tensor(data=0.12770167239445138, grad=0.0)\n",
            "loss in iteration750: Tensor(data=0.12769179640482997, grad=0.0)\n",
            "loss in iteration751: Tensor(data=0.12768202486055022, grad=0.0)\n",
            "loss in iteration752: Tensor(data=0.12767235662426402, grad=0.0)\n",
            "loss in iteration753: Tensor(data=0.1276627905716552, grad=0.0)\n",
            "loss in iteration754: Tensor(data=0.1276533255912786, grad=0.0)\n",
            "loss in iteration755: Tensor(data=0.12764396058440045, grad=0.0)\n",
            "loss in iteration756: Tensor(data=0.12763469446484016, grad=0.0)\n",
            "loss in iteration757: Tensor(data=0.12762552615881642, grad=0.0)\n",
            "loss in iteration758: Tensor(data=0.12761645460479334, grad=0.0)\n",
            "loss in iteration759: Tensor(data=0.1276074787533297, grad=0.0)\n",
            "loss in iteration760: Tensor(data=0.1275985975669303, grad=0.0)\n",
            "loss in iteration761: Tensor(data=0.1275898100198988, grad=0.0)\n",
            "loss in iteration762: Tensor(data=0.12758111509819312, grad=0.0)\n",
            "loss in iteration763: Tensor(data=0.12757251179928256, grad=0.0)\n",
            "loss in iteration764: Tensor(data=0.12756399913200678, grad=0.0)\n",
            "loss in iteration765: Tensor(data=0.1275555761164369, grad=0.0)\n",
            "loss in iteration766: Tensor(data=0.1275472417837385, grad=0.0)\n",
            "loss in iteration767: Tensor(data=0.127538995176036, grad=0.0)\n",
            "loss in iteration768: Tensor(data=0.12753083534627951, grad=0.0)\n",
            "loss in iteration769: Tensor(data=0.12752276135811355, grad=0.0)\n",
            "loss in iteration770: Tensor(data=0.1275147722857462, grad=0.0)\n",
            "loss in iteration771: Tensor(data=0.12750686721382187, grad=0.0)\n",
            "loss in iteration772: Tensor(data=0.12749904523729486, grad=0.0)\n",
            "loss in iteration773: Tensor(data=0.12749130546130394, grad=0.0)\n",
            "loss in iteration774: Tensor(data=0.1274836470010502, grad=0.0)\n",
            "loss in iteration775: Tensor(data=0.12747606898167513, grad=0.0)\n",
            "loss in iteration776: Tensor(data=0.12746857053814084, grad=0.0)\n",
            "loss in iteration777: Tensor(data=0.12746115081511228, grad=0.0)\n",
            "loss in iteration778: Tensor(data=0.12745380896684025, grad=0.0)\n",
            "loss in iteration779: Tensor(data=0.1274465441570466, grad=0.0)\n",
            "loss in iteration780: Tensor(data=0.1274393555588103, grad=0.0)\n",
            "loss in iteration781: Tensor(data=0.12743224235445588, grad=0.0)\n",
            "loss in iteration782: Tensor(data=0.12742520373544267, grad=0.0)\n",
            "loss in iteration783: Tensor(data=0.12741823890225545, grad=0.0)\n",
            "loss in iteration784: Tensor(data=0.1274113470642974, grad=0.0)\n",
            "loss in iteration785: Tensor(data=0.12740452743978326, grad=0.0)\n",
            "loss in iteration786: Tensor(data=0.1273977792556345, grad=0.0)\n",
            "loss in iteration787: Tensor(data=0.1273911017473764, grad=0.0)\n",
            "loss in iteration788: Tensor(data=0.12738449415903513, grad=0.0)\n",
            "loss in iteration789: Tensor(data=0.12737795574303795, grad=0.0)\n",
            "loss in iteration790: Tensor(data=0.12737148576011217, grad=0.0)\n",
            "loss in iteration791: Tensor(data=0.1273650834791889, grad=0.0)\n",
            "loss in iteration792: Tensor(data=0.12735874817730444, grad=0.0)\n",
            "loss in iteration793: Tensor(data=0.12735247913950565, grad=0.0)\n",
            "loss in iteration794: Tensor(data=0.12734627565875506, grad=0.0)\n",
            "loss in iteration795: Tensor(data=0.12734013703583782, grad=0.0)\n",
            "loss in iteration796: Tensor(data=0.12733406257926974, grad=0.0)\n",
            "loss in iteration797: Tensor(data=0.12732805160520616, grad=0.0)\n",
            "loss in iteration798: Tensor(data=0.12732210343735295, grad=0.0)\n",
            "loss in iteration799: Tensor(data=0.12731621740687718, grad=0.0)\n",
            "loss in iteration800: Tensor(data=0.12731039285232043, grad=0.0)\n",
            "loss in iteration801: Tensor(data=0.12730462911951226, grad=0.0)\n",
            "loss in iteration802: Tensor(data=0.12729892556148492, grad=0.0)\n",
            "loss in iteration803: Tensor(data=0.1272932815383899, grad=0.0)\n",
            "loss in iteration804: Tensor(data=0.12728769641741391, grad=0.0)\n",
            "loss in iteration805: Tensor(data=0.12728216957269803, grad=0.0)\n",
            "loss in iteration806: Tensor(data=0.12727670038525624, grad=0.0)\n",
            "loss in iteration807: Tensor(data=0.12727128824289557, grad=0.0)\n",
            "loss in iteration808: Tensor(data=0.12726593254013746, grad=0.0)\n",
            "loss in iteration809: Tensor(data=0.1272606326781397, grad=0.0)\n",
            "loss in iteration810: Tensor(data=0.12725538806461975, grad=0.0)\n",
            "loss in iteration811: Tensor(data=0.12725019811377866, grad=0.0)\n",
            "loss in iteration812: Tensor(data=0.12724506224622636, grad=0.0)\n",
            "loss in iteration813: Tensor(data=0.1272399798889072, grad=0.0)\n",
            "loss in iteration814: Tensor(data=0.12723495047502736, grad=0.0)\n",
            "loss in iteration815: Tensor(data=0.12722997344398254, grad=0.0)\n",
            "loss in iteration816: Tensor(data=0.1272250482412868, grad=0.0)\n",
            "loss in iteration817: Tensor(data=0.1272201743185017, grad=0.0)\n",
            "loss in iteration818: Tensor(data=0.12721535113316748, grad=0.0)\n",
            "loss in iteration819: Tensor(data=0.1272105781487339, grad=0.0)\n",
            "loss in iteration820: Tensor(data=0.12720585483449298, grad=0.0)\n",
            "loss in iteration821: Tensor(data=0.12720118066551162, grad=0.0)\n",
            "loss in iteration822: Tensor(data=0.12719655512256567, grad=0.0)\n",
            "loss in iteration823: Tensor(data=0.12719197769207488, grad=0.0)\n",
            "loss in iteration824: Tensor(data=0.127187447866038, grad=0.0)\n",
            "loss in iteration825: Tensor(data=0.1271829651419694, grad=0.0)\n",
            "loss in iteration826: Tensor(data=0.12717852902283616, grad=0.0)\n",
            "loss in iteration827: Tensor(data=0.12717413901699584, grad=0.0)\n",
            "loss in iteration828: Tensor(data=0.12716979463813524, grad=0.0)\n",
            "loss in iteration829: Tensor(data=0.12716549540520983, grad=0.0)\n",
            "loss in iteration830: Tensor(data=0.12716124084238387, grad=0.0)\n",
            "loss in iteration831: Tensor(data=0.12715703047897098, grad=0.0)\n",
            "loss in iteration832: Tensor(data=0.12715286384937632, grad=0.0)\n",
            "loss in iteration833: Tensor(data=0.1271487404930387, grad=0.0)\n",
            "loss in iteration834: Tensor(data=0.12714465995437316, grad=0.0)\n",
            "loss in iteration835: Tensor(data=0.1271406217827153, grad=0.0)\n",
            "loss in iteration836: Tensor(data=0.12713662553226535, grad=0.0)\n",
            "loss in iteration837: Tensor(data=0.12713267076203352, grad=0.0)\n",
            "loss in iteration838: Tensor(data=0.12712875703578522, grad=0.0)\n",
            "loss in iteration839: Tensor(data=0.1271248839219882, grad=0.0)\n",
            "loss in iteration840: Tensor(data=0.12712105099375892, grad=0.0)\n",
            "loss in iteration841: Tensor(data=0.12711725782881061, grad=0.0)\n",
            "loss in iteration842: Tensor(data=0.12711350400940152, grad=0.0)\n",
            "loss in iteration843: Tensor(data=0.12710978912228396, grad=0.0)\n",
            "loss in iteration844: Tensor(data=0.12710611275865355, grad=0.0)\n",
            "loss in iteration845: Tensor(data=0.12710247451409973, grad=0.0)\n",
            "loss in iteration846: Tensor(data=0.12709887398855652, grad=0.0)\n",
            "loss in iteration847: Tensor(data=0.1270953107862534, grad=0.0)\n",
            "loss in iteration848: Tensor(data=0.1270917845156681, grad=0.0)\n",
            "loss in iteration849: Tensor(data=0.12708829478947817, grad=0.0)\n",
            "loss in iteration850: Tensor(data=0.12708484122451472, grad=0.0)\n",
            "loss in iteration851: Tensor(data=0.12708142344171594, grad=0.0)\n",
            "loss in iteration852: Tensor(data=0.12707804106608117, grad=0.0)\n",
            "loss in iteration853: Tensor(data=0.12707469372662555, grad=0.0)\n",
            "loss in iteration854: Tensor(data=0.12707138105633567, grad=0.0)\n",
            "loss in iteration855: Tensor(data=0.12706810269212496, grad=0.0)\n",
            "loss in iteration856: Tensor(data=0.12706485827479033, grad=0.0)\n",
            "loss in iteration857: Tensor(data=0.12706164744896903, grad=0.0)\n",
            "loss in iteration858: Tensor(data=0.1270584698630957, grad=0.0)\n",
            "loss in iteration859: Tensor(data=0.1270553251693604, grad=0.0)\n",
            "loss in iteration860: Tensor(data=0.12705221302366723, grad=0.0)\n",
            "loss in iteration861: Tensor(data=0.127049133085593, grad=0.0)\n",
            "loss in iteration862: Tensor(data=0.12704608501834638, grad=0.0)\n",
            "loss in iteration863: Tensor(data=0.12704306848872787, grad=0.0)\n",
            "loss in iteration864: Tensor(data=0.1270400831670903, grad=0.0)\n",
            "loss in iteration865: Tensor(data=0.12703712872729941, grad=0.0)\n",
            "loss in iteration866: Tensor(data=0.12703420484669475, grad=0.0)\n",
            "loss in iteration867: Tensor(data=0.12703131120605216, grad=0.0)\n",
            "loss in iteration868: Tensor(data=0.12702844748954495, grad=0.0)\n",
            "loss in iteration869: Tensor(data=0.12702561338470725, grad=0.0)\n",
            "loss in iteration870: Tensor(data=0.1270228085823965, grad=0.0)\n",
            "loss in iteration871: Tensor(data=0.12702003277675727, grad=0.0)\n",
            "loss in iteration872: Tensor(data=0.12701728566518466, grad=0.0)\n",
            "loss in iteration873: Tensor(data=0.127014566948289, grad=0.0)\n",
            "loss in iteration874: Tensor(data=0.12701187632986038, grad=0.0)\n",
            "loss in iteration875: Tensor(data=0.12700921351683392, grad=0.0)\n",
            "loss in iteration876: Tensor(data=0.12700657821925487, grad=0.0)\n",
            "loss in iteration877: Tensor(data=0.12700397015024503, grad=0.0)\n",
            "loss in iteration878: Tensor(data=0.12700138902596844, grad=0.0)\n",
            "loss in iteration879: Tensor(data=0.12699883456559907, grad=0.0)\n",
            "loss in iteration880: Tensor(data=0.12699630649128674, grad=0.0)\n",
            "loss in iteration881: Tensor(data=0.12699380452812545, grad=0.0)\n",
            "loss in iteration882: Tensor(data=0.12699132840412056, grad=0.0)\n",
            "loss in iteration883: Tensor(data=0.1269888778501577, grad=0.0)\n",
            "loss in iteration884: Tensor(data=0.12698645259997082, grad=0.0)\n",
            "loss in iteration885: Tensor(data=0.12698405239011126, grad=0.0)\n",
            "loss in iteration886: Tensor(data=0.12698167695991705, grad=0.0)\n",
            "loss in iteration887: Tensor(data=0.12697932605148252, grad=0.0)\n",
            "loss in iteration888: Tensor(data=0.12697699940962856, grad=0.0)\n",
            "loss in iteration889: Tensor(data=0.12697469678187248, grad=0.0)\n",
            "loss in iteration890: Tensor(data=0.1269724179183993, grad=0.0)\n",
            "loss in iteration891: Tensor(data=0.1269701625720318, grad=0.0)\n",
            "loss in iteration892: Tensor(data=0.12696793049820307, grad=0.0)\n",
            "loss in iteration893: Tensor(data=0.12696572145492716, grad=0.0)\n",
            "loss in iteration894: Tensor(data=0.12696353520277182, grad=0.0)\n",
            "loss in iteration895: Tensor(data=0.12696137150483022, grad=0.0)\n",
            "loss in iteration896: Tensor(data=0.1269592301266938, grad=0.0)\n",
            "loss in iteration897: Tensor(data=0.1269571108364255, grad=0.0)\n",
            "loss in iteration898: Tensor(data=0.12695501340453255, grad=0.0)\n",
            "loss in iteration899: Tensor(data=0.12695293760394002, grad=0.0)\n",
            "loss in iteration900: Tensor(data=0.12695088320996545, grad=0.0)\n",
            "loss in iteration901: Tensor(data=0.12694885000029185, grad=0.0)\n",
            "loss in iteration902: Tensor(data=0.12694683775494278, grad=0.0)\n",
            "loss in iteration903: Tensor(data=0.1269448462562572, grad=0.0)\n",
            "loss in iteration904: Tensor(data=0.12694287528886408, grad=0.0)\n",
            "loss in iteration905: Tensor(data=0.12694092463965792, grad=0.0)\n",
            "loss in iteration906: Tensor(data=0.12693899409777423, grad=0.0)\n",
            "loss in iteration907: Tensor(data=0.12693708345456559, grad=0.0)\n",
            "loss in iteration908: Tensor(data=0.1269351925035774, grad=0.0)\n",
            "loss in iteration909: Tensor(data=0.12693332104052465, grad=0.0)\n",
            "loss in iteration910: Tensor(data=0.12693146886326825, grad=0.0)\n",
            "loss in iteration911: Tensor(data=0.12692963577179223, grad=0.0)\n",
            "loss in iteration912: Tensor(data=0.12692782156818064, grad=0.0)\n",
            "loss in iteration913: Tensor(data=0.12692602605659503, grad=0.0)\n",
            "loss in iteration914: Tensor(data=0.12692424904325258, grad=0.0)\n",
            "loss in iteration915: Tensor(data=0.12692249033640332, grad=0.0)\n",
            "loss in iteration916: Tensor(data=0.1269207497463089, grad=0.0)\n",
            "loss in iteration917: Tensor(data=0.12691902708522057, grad=0.0)\n",
            "loss in iteration918: Tensor(data=0.12691732216735815, grad=0.0)\n",
            "loss in iteration919: Tensor(data=0.1269156348088888, grad=0.0)\n",
            "loss in iteration920: Tensor(data=0.12691396482790634, grad=0.0)\n",
            "loss in iteration921: Tensor(data=0.1269123120444103, grad=0.0)\n",
            "loss in iteration922: Tensor(data=0.1269106762802855, grad=0.0)\n",
            "loss in iteration923: Tensor(data=0.12690905735928254, grad=0.0)\n",
            "loss in iteration924: Tensor(data=0.1269074551069972, grad=0.0)\n",
            "loss in iteration925: Tensor(data=0.12690586935085052, grad=0.0)\n",
            "loss in iteration926: Tensor(data=0.12690429992007024, grad=0.0)\n",
            "loss in iteration927: Tensor(data=0.12690274664567053, grad=0.0)\n",
            "loss in iteration928: Tensor(data=0.12690120936043364, grad=0.0)\n",
            "loss in iteration929: Tensor(data=0.12689968789889022, grad=0.0)\n",
            "loss in iteration930: Tensor(data=0.12689818209730164, grad=0.0)\n",
            "loss in iteration931: Tensor(data=0.12689669179364074, grad=0.0)\n",
            "loss in iteration932: Tensor(data=0.12689521682757396, grad=0.0)\n",
            "loss in iteration933: Tensor(data=0.12689375704044345, grad=0.0)\n",
            "loss in iteration934: Tensor(data=0.12689231227524864, grad=0.0)\n",
            "loss in iteration935: Tensor(data=0.12689088237662924, grad=0.0)\n",
            "loss in iteration936: Tensor(data=0.1268894671908472, grad=0.0)\n",
            "loss in iteration937: Tensor(data=0.12688806656576998, grad=0.0)\n",
            "loss in iteration938: Tensor(data=0.12688668035085313, grad=0.0)\n",
            "loss in iteration939: Tensor(data=0.12688530839712367, grad=0.0)\n",
            "loss in iteration940: Tensor(data=0.12688395055716295, grad=0.0)\n",
            "loss in iteration941: Tensor(data=0.12688260668509066, grad=0.0)\n",
            "loss in iteration942: Tensor(data=0.126881276636548, grad=0.0)\n",
            "loss in iteration943: Tensor(data=0.1268799602686822, grad=0.0)\n",
            "loss in iteration944: Tensor(data=0.12687865744012952, grad=0.0)\n",
            "loss in iteration945: Tensor(data=0.12687736801100058, grad=0.0)\n",
            "loss in iteration946: Tensor(data=0.1268760918428639, grad=0.0)\n",
            "loss in iteration947: Tensor(data=0.12687482879873077, grad=0.0)\n",
            "loss in iteration948: Tensor(data=0.12687357874304014, grad=0.0)\n",
            "loss in iteration949: Tensor(data=0.12687234154164287, grad=0.0)\n",
            "loss in iteration950: Tensor(data=0.1268711170617874, grad=0.0)\n",
            "loss in iteration951: Tensor(data=0.12686990517210506, grad=0.0)\n",
            "loss in iteration952: Tensor(data=0.1268687057425946, grad=0.0)\n",
            "loss in iteration953: Tensor(data=0.1268675186446083, grad=0.0)\n",
            "loss in iteration954: Tensor(data=0.12686634375083786, grad=0.0)\n",
            "loss in iteration955: Tensor(data=0.12686518093529994, grad=0.0)\n",
            "loss in iteration956: Tensor(data=0.12686403007332178, grad=0.0)\n",
            "loss in iteration957: Tensor(data=0.12686289104152823, grad=0.0)\n",
            "loss in iteration958: Tensor(data=0.12686176371782729, grad=0.0)\n",
            "loss in iteration959: Tensor(data=0.12686064798139696, grad=0.0)\n",
            "loss in iteration960: Tensor(data=0.12685954371267147, grad=0.0)\n",
            "loss in iteration961: Tensor(data=0.1268584507933286, grad=0.0)\n",
            "loss in iteration962: Tensor(data=0.126857369106276, grad=0.0)\n",
            "loss in iteration963: Tensor(data=0.12685629853563843, grad=0.0)\n",
            "loss in iteration964: Tensor(data=0.12685523896674486, grad=0.0)\n",
            "loss in iteration965: Tensor(data=0.12685419028611603, grad=0.0)\n",
            "loss in iteration966: Tensor(data=0.12685315238145167, grad=0.0)\n",
            "loss in iteration967: Tensor(data=0.126852125141618, grad=0.0)\n",
            "loss in iteration968: Tensor(data=0.12685110845663547, grad=0.0)\n",
            "loss in iteration969: Tensor(data=0.12685010221766696, grad=0.0)\n",
            "loss in iteration970: Tensor(data=0.12684910631700533, grad=0.0)\n",
            "loss in iteration971: Tensor(data=0.1268481206480617, grad=0.0)\n",
            "loss in iteration972: Tensor(data=0.12684714510535347, grad=0.0)\n",
            "loss in iteration973: Tensor(data=0.1268461795844933, grad=0.0)\n",
            "loss in iteration974: Tensor(data=0.1268452239821768, grad=0.0)\n",
            "loss in iteration975: Tensor(data=0.12684427819617164, grad=0.0)\n",
            "loss in iteration976: Tensor(data=0.12684334212530615, grad=0.0)\n",
            "loss in iteration977: Tensor(data=0.12684241566945825, grad=0.0)\n",
            "loss in iteration978: Tensor(data=0.12684149872954423, grad=0.0)\n",
            "loss in iteration979: Tensor(data=0.12684059120750804, grad=0.0)\n",
            "loss in iteration980: Tensor(data=0.1268396930063105, grad=0.0)\n",
            "loss in iteration981: Tensor(data=0.12683880402991848, grad=0.0)\n",
            "loss in iteration982: Tensor(data=0.12683792418329434, grad=0.0)\n",
            "loss in iteration983: Tensor(data=0.12683705337238574, grad=0.0)\n",
            "loss in iteration984: Tensor(data=0.12683619150411507, grad=0.0)\n",
            "loss in iteration985: Tensor(data=0.12683533848636916, grad=0.0)\n",
            "loss in iteration986: Tensor(data=0.12683449422798956, grad=0.0)\n",
            "loss in iteration987: Tensor(data=0.1268336586387618, grad=0.0)\n",
            "loss in iteration988: Tensor(data=0.12683283162940664, grad=0.0)\n",
            "loss in iteration989: Tensor(data=0.12683201311156905, grad=0.0)\n",
            "loss in iteration990: Tensor(data=0.12683120299780923, grad=0.0)\n",
            "loss in iteration991: Tensor(data=0.12683040120159314, grad=0.0)\n",
            "loss in iteration992: Tensor(data=0.1268296076372822, grad=0.0)\n",
            "loss in iteration993: Tensor(data=0.12682882222012512, grad=0.0)\n",
            "loss in iteration994: Tensor(data=0.12682804486624735, grad=0.0)\n",
            "loss in iteration995: Tensor(data=0.12682727549264303, grad=0.0)\n",
            "loss in iteration996: Tensor(data=0.12682651401716505, grad=0.0)\n",
            "loss in iteration997: Tensor(data=0.12682576035851648, grad=0.0)\n",
            "loss in iteration998: Tensor(data=0.12682501443624183, grad=0.0)\n",
            "loss in iteration999: Tensor(data=0.12682427617071784, grad=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_arr = []\n",
        "for i in range(len(X_test)):\n",
        "    output = model(X_test[i])\n",
        "    t_arr.append(output)\n",
        "    print(output, \" label: \",y_test[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18iDdKHRrxbR",
        "outputId": "51a086a4-9a93-472b-d8c9-5406cd2e78df"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(data=0.427579910573807, grad=0.0)  label:  0.5\n",
            "Tensor(data=0.29344108648963274, grad=0.0)  label:  0.0\n",
            "Tensor(data=0.45440188753641486, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.40575142674573095, grad=0.0)  label:  0.5\n",
            "Tensor(data=0.447446477318138, grad=0.0)  label:  0.5\n",
            "Tensor(data=0.27887580810822904, grad=0.0)  label:  0.0\n",
            "Tensor(data=0.37079684657592804, grad=0.0)  label:  0.5\n",
            "Tensor(data=0.41982535453717734, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.442931835425493, grad=0.0)  label:  0.5\n",
            "Tensor(data=0.40797976037188216, grad=0.0)  label:  0.5\n",
            "Tensor(data=0.4094148310989484, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.25290233609094454, grad=0.0)  label:  0.0\n",
            "Tensor(data=0.2931286373051527, grad=0.0)  label:  0.0\n",
            "Tensor(data=0.2625155699652565, grad=0.0)  label:  0.0\n",
            "Tensor(data=0.1438984244418655, grad=0.0)  label:  0.0\n",
            "Tensor(data=0.4029140247874346, grad=0.0)  label:  0.5\n",
            "Tensor(data=0.41762396797458423, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.4111826622693922, grad=0.0)  label:  0.5\n",
            "Tensor(data=0.4011064408006054, grad=0.0)  label:  0.5\n",
            "Tensor(data=0.4182369672066862, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.18810146483354484, grad=0.0)  label:  0.0\n",
            "Tensor(data=0.4021128090662926, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.19704871463420068, grad=0.0)  label:  0.0\n",
            "Tensor(data=0.42054109674724544, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.4413054169839078, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.416880460947172, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.44556880032500956, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.4204025724576714, grad=0.0)  label:  1.0\n",
            "Tensor(data=0.22644744806727476, grad=0.0)  label:  0.0\n",
            "Tensor(data=0.23348600841228867, grad=0.0)  label:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preforming predictions"
      ],
      "metadata": {
        "id": "zQo-n6Eswi7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "for t in t_arr:\n",
        "    y_pred.append(t.data)\n",
        "y_pred = np.array(y_pred)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t4p7NUps-vc",
        "outputId": "f51fd7b6-3a1e-49ce-995a-0d0342211d4f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.42757991, 0.29344109, 0.45440189, 0.40575143, 0.44744648,\n",
              "       0.27887581, 0.37079685, 0.41982535, 0.44293184, 0.40797976,\n",
              "       0.40941483, 0.25290234, 0.29312864, 0.26251557, 0.14389842,\n",
              "       0.40291402, 0.41762397, 0.41118266, 0.40110644, 0.41823697,\n",
              "       0.18810146, 0.40211281, 0.19704871, 0.4205411 , 0.44130542,\n",
              "       0.41688046, 0.4455688 , 0.42040257, 0.22644745, 0.23348601])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation with r2 score"
      ],
      "metadata": {
        "id": "scCGKJdrwlIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_3qm3L5r38S",
        "outputId": "96191493-db18-4695-9fa8-ec8d8d89e386"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17865661907655495"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}